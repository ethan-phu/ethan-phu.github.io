<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>RAG系列-语义分块RAG（Semantic Chunking RAG） - Ethan's Blog</title><meta name=Description content="This is my cool site"><meta property="og:url" content="https://ethan-phu.github.io/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag/">
<meta property="og:site_name" content="Ethan's Blog"><meta property="og:title" content="RAG系列-语义分块RAG（Semantic Chunking RAG）"><meta property="og:description" content="02. 语义分块RAG（Semantic Chunking RAG） 方法简介 语义分块RAG通过计算句子间的语义相似度来智能分块，而不是简单的固定长度分块。它使用百分"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-18T00:00:00+08:00"><meta property="article:tag" content="技术"><meta property="article:tag" content="RAG"><meta property="article:tag" content="笔记"><meta name=twitter:card content="summary"><meta name=twitter:title content="RAG系列-语义分块RAG（Semantic Chunking RAG）"><meta name=twitter:description content="02. 语义分块RAG（Semantic Chunking RAG） 方法简介 语义分块RAG通过计算句子间的语义相似度来智能分块，而不是简单的固定长度分块。它使用百分"><meta name=application-name content="My cool site"><meta name=apple-mobile-web-app-title content="My cool site"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://ethan-phu.github.io/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag/><link rel=prev href=https://ethan-phu.github.io/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/><link rel=next href=https://ethan-phu.github.io/%E5%9F%BA%E7%A1%80rag/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"RAG系列-语义分块RAG（Semantic Chunking RAG）","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/ethan-phu.github.io\/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag\/"},"genre":"posts","keywords":"技术, RAG, 笔记","wordcount":1446,"url":"https:\/\/ethan-phu.github.io\/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag\/","datePublished":"2025-06-18T00:00:00+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"作者"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Ethan's Blog">Ethan</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/ title=文章>文章 </a><a class=menu-item href=/weekly title=兴趣周刊>周刊 </a><a class=menu-item href=/categories title=分类>分类 </a><a class=menu-item href=/tags title=标签>标签 </a><a class=menu-item href=/about/ title=关于ethan>关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Ethan's Blog">Ethan</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></div><a class=menu-item href=/posts/ title=文章>文章</a><a class=menu-item href=/weekly title=兴趣周刊>周刊</a><a class=menu-item href=/categories title=分类>分类</a><a class=menu-item href=/tags title=标签>标签</a><a class=menu-item href=/about/ title=关于ethan>关于</a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">RAG系列-语义分块RAG（Semantic Chunking RAG）</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>作者</a></span>&nbsp;<span class=post-category>收录于 <a href=/categories/%E6%8A%80%E6%9C%AF/><i class="far fa-folder fa-fw" aria-hidden=true></i>技术</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2025-06-18>2025-06-18</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;约 1446 字&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;预计阅读 3 分钟&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#方法简介>方法简介</a></li><li><a href=#核心代码>核心代码</a></li><li><a href=#代码讲解>代码讲解</a></li><li><a href=#主要特点>主要特点</a></li><li><a href=#使用场景>使用场景</a></li></ul></nav></div></div><div class=content id=content><h1 id=02-语义分块ragsemantic-chunking-rag>02. 语义分块RAG（Semantic Chunking RAG）</h1><h2 id=方法简介>方法简介</h2><p>语义分块RAG通过计算句子间的语义相似度来智能分块，而不是简单的固定长度分块。它使用百分位数、标准差或四分位距等方法找到语义断点，将文本分割成语义连贯的块，提升检索精度。</p><h2 id=核心代码>核心代码</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>fitz</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_text_from_pdf</span><span class=p>(</span><span class=n>pdf_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Extracts text from a PDF file.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    pdf_path (str): Path to the PDF file.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    str: Extracted text from the PDF.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># Open the PDF file</span>
</span></span><span class=line><span class=cl>    <span class=n>mypdf</span> <span class=o>=</span> <span class=n>fitz</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>pdf_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>all_text</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>  <span class=c1># Initialize an empty string to store the extracted text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Iterate through each page in the PDF</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>page</span> <span class=ow>in</span> <span class=n>mypdf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Extract text from the current page and add spacing</span>
</span></span><span class=line><span class=cl>        <span class=n>all_text</span> <span class=o>+=</span> <span class=n>page</span><span class=o>.</span><span class=n>get_text</span><span class=p>(</span><span class=s2>&#34;text&#34;</span><span class=p>)</span> <span class=o>+</span> <span class=s2>&#34; &#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Return the extracted text, stripped of leading/trailing whitespace</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>all_text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the OpenAI client with the base URL and API key</span>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>base_url</span><span class=o>=</span><span class=s2>&#34;https://api.studio.nebius.com/v1/&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;OPENAI_API_KEY&#34;</span><span class=p>)</span>  <span class=c1># Retrieve the API key from environment variables</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_embedding</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&#34;BAAI/bge-en-icl&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Creates an embedding for the given text using OpenAI.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    text (str): Input text.
</span></span></span><span class=line><span class=cl><span class=s2>    model (str): Embedding model name.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    np.ndarray: The embedding vector.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>embeddings</span><span class=o>.</span><span class=n>create</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span> <span class=nb>input</span><span class=o>=</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>embedding</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cosine_similarity</span><span class=p>(</span><span class=n>vec1</span><span class=p>,</span> <span class=n>vec2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Computes cosine similarity between two vectors.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    vec1 (np.ndarray): First vector.
</span></span></span><span class=line><span class=cl><span class=s2>    vec2 (np.ndarray): Second vector.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    float: Cosine similarity.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>vec1</span><span class=p>,</span> <span class=n>vec2</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>vec1</span><span class=p>)</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>vec2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_breakpoints</span><span class=p>(</span><span class=n>similarities</span><span class=p>,</span> <span class=n>method</span><span class=o>=</span><span class=s2>&#34;percentile&#34;</span><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=mi>90</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Computes chunking breakpoints based on similarity drops.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    similarities (List[float]): List of similarity scores between sentences.
</span></span></span><span class=line><span class=cl><span class=s2>    method (str): &#39;percentile&#39;, &#39;standard_deviation&#39;, or &#39;interquartile&#39;.
</span></span></span><span class=line><span class=cl><span class=s2>    threshold (float): Threshold value (percentile for &#39;percentile&#39;, std devs for &#39;standard_deviation&#39;).
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    List[int]: Indices where chunk splits should occur.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># Determine the threshold value based on the selected method</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&#34;percentile&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Calculate the Xth percentile of the similarity scores</span>
</span></span><span class=line><span class=cl>        <span class=n>threshold_value</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>similarities</span><span class=p>,</span> <span class=n>threshold</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&#34;standard_deviation&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Calculate the mean and standard deviation of the similarity scores</span>
</span></span><span class=line><span class=cl>        <span class=n>mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>similarities</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>std_dev</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>similarities</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Set the threshold value to mean minus X standard deviations</span>
</span></span><span class=line><span class=cl>        <span class=n>threshold_value</span> <span class=o>=</span> <span class=n>mean</span> <span class=o>-</span> <span class=p>(</span><span class=n>threshold</span> <span class=o>*</span> <span class=n>std_dev</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s2>&#34;interquartile&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Calculate the first and third quartiles (Q1 and Q3)</span>
</span></span><span class=line><span class=cl>        <span class=n>q1</span><span class=p>,</span> <span class=n>q3</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>similarities</span><span class=p>,</span> <span class=p>[</span><span class=mi>25</span><span class=p>,</span> <span class=mi>75</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=c1># Set the threshold value using the IQR rule for outliers</span>
</span></span><span class=line><span class=cl>        <span class=n>threshold_value</span> <span class=o>=</span> <span class=n>q1</span> <span class=o>-</span> <span class=mf>1.5</span> <span class=o>*</span> <span class=p>(</span><span class=n>q3</span> <span class=o>-</span> <span class=n>q1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Raise an error if an invalid method is provided</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;Invalid method. Choose &#39;percentile&#39;, &#39;standard_deviation&#39;, or &#39;interquartile&#39;.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Identify indices where similarity drops below the threshold value</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>sim</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>similarities</span><span class=p>)</span> <span class=k>if</span> <span class=n>sim</span> <span class=o>&lt;</span> <span class=n>threshold_value</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>split_into_chunks</span><span class=p>(</span><span class=n>sentences</span><span class=p>,</span> <span class=n>breakpoints</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Splits sentences into semantic chunks.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    sentences (List[str]): List of sentences.
</span></span></span><span class=line><span class=cl><span class=s2>    breakpoints (List[int]): Indices where chunking should occur.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    List[str]: List of text chunks.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>chunks</span> <span class=o>=</span> <span class=p>[]</span>  <span class=c1># Initialize an empty list to store the chunks</span>
</span></span><span class=line><span class=cl>    <span class=n>start</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># Initialize the start index</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Iterate through each breakpoint to create chunks</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>bp</span> <span class=ow>in</span> <span class=n>breakpoints</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Append the chunk of sentences from start to the current breakpoint</span>
</span></span><span class=line><span class=cl>        <span class=n>chunks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s2>&#34;. &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>sentences</span><span class=p>[</span><span class=n>start</span><span class=p>:</span><span class=n>bp</span> <span class=o>+</span> <span class=mi>1</span><span class=p>])</span> <span class=o>+</span> <span class=s2>&#34;.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>start</span> <span class=o>=</span> <span class=n>bp</span> <span class=o>+</span> <span class=mi>1</span>  <span class=c1># Update the start index to the next sentence after the breakpoint</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Append the remaining sentences as the last chunk</span>
</span></span><span class=line><span class=cl>    <span class=n>chunks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s2>&#34;. &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>sentences</span><span class=p>[</span><span class=n>start</span><span class=p>:]))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>chunks</span>  <span class=c1># Return the list of chunks</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_embeddings</span><span class=p>(</span><span class=n>text_chunks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Creates embeddings for each text chunk.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    text_chunks (List[str]): List of text chunks.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    List[np.ndarray]: List of embedding vectors.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># Generate embeddings for each text chunk using the get_embedding function</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span><span class=n>get_embedding</span><span class=p>(</span><span class=n>chunk</span><span class=p>)</span> <span class=k>for</span> <span class=n>chunk</span> <span class=ow>in</span> <span class=n>text_chunks</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>semantic_search</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>text_chunks</span><span class=p>,</span> <span class=n>chunk_embeddings</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Finds the most relevant text chunks for a query.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    query (str): Search query.
</span></span></span><span class=line><span class=cl><span class=s2>    text_chunks (List[str]): List of text chunks.
</span></span></span><span class=line><span class=cl><span class=s2>    chunk_embeddings (List[np.ndarray]): List of chunk embeddings.
</span></span></span><span class=line><span class=cl><span class=s2>    k (int): Number of top results to return.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    List[str]: Top-k relevant chunks.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># Generate an embedding for the query</span>
</span></span><span class=line><span class=cl>    <span class=n>query_embedding</span> <span class=o>=</span> <span class=n>get_embedding</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Calculate cosine similarity between the query embedding and each chunk embedding</span>
</span></span><span class=line><span class=cl>    <span class=n>similarities</span> <span class=o>=</span> <span class=p>[</span><span class=n>cosine_similarity</span><span class=p>(</span><span class=n>query_embedding</span><span class=p>,</span> <span class=n>emb</span><span class=p>)</span> <span class=k>for</span> <span class=n>emb</span> <span class=ow>in</span> <span class=n>chunk_embeddings</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Get the indices of the top-k most similar chunks</span>
</span></span><span class=line><span class=cl>    <span class=n>top_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>similarities</span><span class=p>)[</span><span class=o>-</span><span class=n>k</span><span class=p>:][::</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Return the top-k most relevant text chunks</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span><span class=n>text_chunks</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>top_indices</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_response</span><span class=p>(</span><span class=n>system_prompt</span><span class=p>,</span> <span class=n>user_message</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&#34;meta-llama/Llama-3.2-3B-Instruct&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Generates a response from the AI model based on the system prompt and user message.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>    system_prompt (str): The system prompt to guide the AI&#39;s behavior.
</span></span></span><span class=line><span class=cl><span class=s2>    user_message (str): The user&#39;s message or query.
</span></span></span><span class=line><span class=cl><span class=s2>    model (str): The model to be used for generating the response. Default is &#34;meta-llama/Llama-2-7B-chat-hf&#34;.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>    dict: The response from the AI model.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>system_prompt</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>user_message</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 完整调用流程</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>semantic_chunking_rag_pipeline</span><span class=p>(</span><span class=n>pdf_path</span><span class=p>,</span> <span class=n>query</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 提取PDF文本</span>
</span></span><span class=line><span class=cl>    <span class=n>extracted_text</span> <span class=o>=</span> <span class=n>extract_text_from_pdf</span><span class=p>(</span><span class=n>pdf_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. 按句子分割</span>
</span></span><span class=line><span class=cl>    <span class=n>sentences</span> <span class=o>=</span> <span class=n>extracted_text</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;. &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3. 生成句子嵌入</span>
</span></span><span class=line><span class=cl>    <span class=n>embeddings</span> <span class=o>=</span> <span class=p>[</span><span class=n>get_embedding</span><span class=p>(</span><span class=n>sentence</span><span class=p>)</span> <span class=k>for</span> <span class=n>sentence</span> <span class=ow>in</span> <span class=n>sentences</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 4. 计算句子间相似度</span>
</span></span><span class=line><span class=cl>    <span class=n>similarities</span> <span class=o>=</span> <span class=p>[</span><span class=n>cosine_similarity</span><span class=p>(</span><span class=n>embeddings</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>embeddings</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>])</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>embeddings</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 5. 计算断点（使用百分位数方法）</span>
</span></span><span class=line><span class=cl>    <span class=n>breakpoints</span> <span class=o>=</span> <span class=n>compute_breakpoints</span><span class=p>(</span><span class=n>similarities</span><span class=p>,</span> <span class=n>method</span><span class=o>=</span><span class=s2>&#34;percentile&#34;</span><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=mi>90</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 6. 分割成语义块</span>
</span></span><span class=line><span class=cl>    <span class=n>text_chunks</span> <span class=o>=</span> <span class=n>split_into_chunks</span><span class=p>(</span><span class=n>sentences</span><span class=p>,</span> <span class=n>breakpoints</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 7. 创建块嵌入</span>
</span></span><span class=line><span class=cl>    <span class=n>chunk_embeddings</span> <span class=o>=</span> <span class=n>create_embeddings</span><span class=p>(</span><span class=n>text_chunks</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 8. 语义搜索</span>
</span></span><span class=line><span class=cl>    <span class=n>top_chunks</span> <span class=o>=</span> <span class=n>semantic_search</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>text_chunks</span><span class=p>,</span> <span class=n>chunk_embeddings</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 9. 生成回答</span>
</span></span><span class=line><span class=cl>    <span class=n>system_prompt</span> <span class=o>=</span> <span class=s2>&#34;You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: &#39;I do not have enough information to answer that.&#39;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>user_prompt</span> <span class=o>=</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>([</span><span class=sa>f</span><span class=s2>&#34;Context </span><span class=si>{</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=si>}</span><span class=s2>:</span><span class=se>\n</span><span class=si>{</span><span class=n>chunk</span><span class=si>}</span><span class=se>\n</span><span class=s2>=====================================</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>chunk</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>top_chunks</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>    <span class=n>user_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>user_prompt</span><span class=si>}</span><span class=se>\n</span><span class=s2>Question: </span><span class=si>{</span><span class=n>query</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>ai_response</span> <span class=o>=</span> <span class=n>generate_response</span><span class=p>(</span><span class=n>system_prompt</span><span class=p>,</span> <span class=n>user_prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ai_response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=代码讲解>代码讲解</h2><ul><li><strong>句子分割</strong>：按句号分割文本成句子</li><li><strong>嵌入生成</strong>：为每个句子生成向量表示</li><li><strong>相似度计算</strong>：计算相邻句子的余弦相似度</li><li><strong>断点检测</strong>：使用百分位数方法找到语义断点</li><li><strong>语义分块</strong>：根据断点将句子组合成语义块</li><li><strong>检索生成</strong>：基于语义块进行检索和答案生成</li></ul><h2 id=主要特点>主要特点</h2><ul><li>基于语义相似度的智能分块</li><li>支持多种断点检测方法（百分位数、标准差、四分位距）</li><li>保持语义连贯性</li><li>比固定长度分块更精准</li></ul><h2 id=使用场景>使用场景</h2><ul><li>长文档处理</li><li>需要保持语义完整性的场景</li><li>复杂问答系统</li><li>学术论文、技术文档等结构化文本</li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 0001-01-01</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://ethan-phu.github.io/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag/ data-title="RAG系列-语义分块RAG（Semantic Chunking RAG）" data-hashtags=技术,RAG,笔记><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://ethan-phu.github.io/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag/ data-hashtag=技术><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Hacker News" data-sharer=hackernews data-url=https://ethan-phu.github.io/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag/ data-title="RAG系列-语义分块RAG（Semantic Chunking RAG）"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Line" data-sharer=line data-url=https://ethan-phu.github.io/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag/ data-title="RAG系列-语义分块RAG（Semantic Chunking RAG）"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@6.20.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://ethan-phu.github.io/%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97rag/ data-title="RAG系列-语义分块RAG（Semantic Chunking RAG）"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/%E6%8A%80%E6%9C%AF/>技术</a>,&nbsp;<a href=/tags/rag/>RAG</a>,&nbsp;<a href=/tags/%E7%AC%94%E8%AE%B0/>笔记</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/ class=prev rel=prev title=2025年展望><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>2025年展望</a>
<a href=/%E5%9F%BA%E7%A1%80rag/ class=next rel=next title="RAG系列-基础RAG（Simple RAG）">RAG系列-基础RAG（Simple RAG）<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2022 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank></a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lightgallery@2.4.0/css/lightgallery-bundle.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script type=text/javascript src=/lib/lunr/lunr.stemmer.support.min.js></script><script type=text/javascript src=/lib/lunr/lunr.zh.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.1/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.4.0/lightgallery.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.4.0/plugins/thumbnail/lg-thumbnail.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lightgallery@2.4.0/plugins/zoom/lg-zoom.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:100},comment:{},lightgallery:!0,search:{highlightTag:"em",lunrIndexURL:"/index.json",lunrLanguageCode:"zh",lunrSegmentitURL:"/lib/lunr/lunr.segmentit.js",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-TYXZ2Y2RHZ")</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=G-TYXZ2Y2RHZ" async></script></body></html>