[{"categories":["思考"],"content":"当下 本页记录当下我需要专注的事情。更新于2024/10/26 于中国武汉 ","date":"2024-10-26","objectID":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/:0:0","tags":["成长","反思","思考"],"title":"当下的事情","uri":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/"},{"categories":["思考"],"content":"生活 日常工作：练习专注，寻找目标感 项目稳步推进 测试同学的挑衅淡定对待，工作而已 业余生活：稳定作息，健康生活 坚持做饭 有节奏的作息，拒绝熬夜 运动健身：提高基础代谢 开始跑步，每周至少两次 继续羽毛球运动 ","date":"2024-10-26","objectID":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/:1:0","tags":["成长","反思","思考"],"title":"当下的事情","uri":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/"},{"categories":["思考"],"content":"学习 读书： 阅读《build a large language model from scratch》 阅读《真需求》梁宁 技术： 学习深度包解析技术 学习TCP协议相关知识 ","date":"2024-10-26","objectID":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/:2:0","tags":["成长","反思","思考"],"title":"当下的事情","uri":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/"},{"categories":["思考"],"content":"项目 流量采集器 ","date":"2024-10-26","objectID":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/:3:0","tags":["成长","反思","思考"],"title":"当下的事情","uri":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/"},{"categories":["工具"],"content":"This message is used to verify that this feed (feedId:71916462721158158) belongs to me (userId:45764741539537920). Join me in enjoying the next generation information browser https://follow.is. ","date":"2024-10-24","objectID":"/%E8%AE%A4%E8%AF%81follow%E8%AE%A2%E9%98%85%E6%BA%90/:0:0","tags":["工具"],"title":"认证订阅","uri":"/%E8%AE%A4%E8%AF%81follow%E8%AE%A2%E9%98%85%E6%BA%90/"},{"categories":["weekly"],"content":"本周报分享每周所学所知所闻所感，时间范围是 2023-02-13 到 2023-02-19 会记录一些工作及生活上有意思的事情。 本周报每周日晚上发布，会同步到本人博客中 ","date":"2023-02-19","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"2023年第7周, 新的旅途","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/"},{"categories":["weekly"],"content":"见闻 ","date":"2023-02-19","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"2023年第7周, 新的旅途","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/"},{"categories":["weekly"],"content":"为个人开发者实现了一套集成化的收费方案 最近一周在捣腾 RSS 订阅软件的事情，发现市面上可以主动发现独立博客，并可以订阅万物的软件很少，用的很顺滑的工具也非常的少。于是想开发软件来实现，但是服务器维护费用也是非常高的，所以想做一个可以订阅付费，但是作为个人开发者，开通支付渠道门槛非常高。于是在网上摸索了很久，找到了一个基本可行的方案，v2geek「收费5%还是有点高的」。他基本满足我的需求，但是没有提供任何开发的接口，不能和软件体系闭环。于是我采用了爬虫技术，基本实现了平台和软件的闭环，可以达到在软件上支付订阅费用，立马给订阅者分发授权码!一整套操作，不需要任何人工操作。 #coding=utf-8 import requests import re from bs4 import BeautifulSoup import uuid class V2GeeKPay(object): def __init__(self, cookies, project=\"\"): self.cookies = cookies self.headers = { \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\", \"accept-encoding\": \"gzip, deflate, br\", \"accept-language\": \"zh-CN,zh;q=0.9,und;q=0.8,zh-Hans;q=0.7,en;q=0.6\", \"cache-control\": \"max-age=0\", \"cookie\": \"_sessions={}\".format(cookies), \"referer\": \"https://v2geek.com/udmin/projects\", \"sec-ch-ua-mobile\": \"?0\", \"sec-ch-ua-platform\": \"Linux\", \"sec-fetch-dest\": \"document\", \"sec-fetch-mode\": \"navigate\", \"sec-fetch-site\": \"same-origin\", \"sec-fetch-user\": \"?1\", \"upgrade-insecure-requests\": \"1\", } flag, self.project_list, self.user_name = self.get_project_list() if not flag: raise ValueError(\"cookie过期，请检查\") if project != \"\": self.set_project(project) def set_project(self, project): project_exist = False for project_obj in self.project_list: if project_obj[\"key\"] == project: self.pay_js = \"https://v2geek.com/{}/{}/widget.js\".format(self.user_name, project) self.login_url = \"https://v2geek.com/users/sign_in\" self.import_url = \"https://v2geek.com/udmin/projects/{}/licenses/import\".format(project) self.project_url = \"https://v2geek.com/udmin/projects/{}\".format(project) self.order_url = \"https://v2geek.com/udmin/orders\" self.project = project project_exist = True break if not project_exist: raise ValueError(\"当前用户不存在此项目，请检查\") def get_project_list(self): \"\"\"获取当前用户的项目以及用户名\"\"\" project_list_url = \"https://v2geek.com/udmin/projects\" session = requests.Session() try: response = str(session.get(project_list_url, headers=self.headers, verify=False).content, encoding=\"utf-8\") html_obj = BeautifulSoup(response, \"html.parser\") tr_list = html_obj.select(\"tbody\")[0].select(\"tr\") dict_project_info = { 0: \"name\", 1: \"price\" } user_name = \"\" project_list = [] for tr in tr_list: temp = {} for idx, td in enumerate(tr.select(\"td\")): if idx in dict_project_info: pro_key = dict_project_info[idx] temp[pro_key] = td.text.strip().replace(\"￥\",\"\").replace(\"元\",\"\") if pro_key == \"name\": key_list = td.select(\"a\")[0].get(\"href\").split(\"/\") if user_name != \"\": user_name = key_list[1] temp[\"key\"] = key_list[2] project_list.append(temp) return True, project_list, user_name except: return False, [], \"\" def generateAuthToken(self, numbers=100): \"\"\"使用uuid算法自动生成authToken \"\"\" return [uuid.uuid4().hex for i in range(numbers)] def import_auth_token(self, auth_token_list): # 自动生成一系列的auth_token值，并分发到系统以便不断的扩充auth_token的值，并将值存入系统 # 获取token值 saved_token_list, unused_token, rest_token = self.get_auth_token_list() if rest_token != \"\": data = { \"utf8\": (None, \"\u0026#x2713;\"), \"authenticity_token\": (None, rest_token), \"licenses\": (None, \"\\n\".join(auth_token_list)), \"commit\": (None, \"提交\") } session = requests.Session() session.post(self.import_url, data=data, headers=headers, verify=False) print(\"导入成功\") return True, \"success\" else: print(\"cookie过期\") return False, \"cookie已过期，请联系工程师处理\" def get_auth_token_list(self): \"\"\" 获取账户的相关信息，以便能够实时进行激活处理 获取成功则返回当前的token,可以用于导入auth_token \"\"\" session = requests.Session() try: response = str(session.get(self.project_url, headers=self.headers, verify=False).content, encoding=\"utf-8\") html_obj_first = BeautifulSoup(response, \"html.parser\") page = html_obj_first.select(\".pagination\") meta_list = html_obj_first.select(\"meta\") rest_token = \"\" html_obj_list = [html_obj_first] for meta in meta_list: if meta.get(\"name\") == \"csrf-token\": rest_token = meta.get(\"content\") if len(page): page_num = int(page[0].select(\"a\")[-1].get(\"href\").split(\"=\")[1].strip())+1 for i in range(2, page_num): response = str(ses","date":"2023-02-19","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/:1:1","tags":["技术","周报","启示"],"title":"2023年第7周, 新的旅途","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/"},{"categories":["weekly"],"content":"开发一款RSS订阅软件 在这信息爆炸的时代，我们身边围绕着十分多的信息，加上推荐系统不断在为我们构建信息围城，我们需要寻找更好的阅读体验的方式，去打破信息围城，以突破信息边界，让我们和世界的信息差不断缩小。有时候也在迷茫，想寻找更好的资讯渠道，比如优质博主，优质信息。知识付费盛行，导致优质信息获取进一步变得十分困难。所以内心一直在想做一款能够对内容进行涮选的rss订阅软件，来丰富自己的阅读，并提升阅读体验和更快的找到优质的信息。 ","date":"2023-02-19","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/:1:2","tags":["技术","周报","启示"],"title":"2023年第7周, 新的旅途","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/"},{"categories":["weekly"],"content":"本周报分享每周所学所知所闻所感，时间范围是 2023-02-06 到 2023-02-12 会记录一些工作及生活上有意思的事情。 本周报每周日晚上发布，会同步到本人博客中 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"见闻 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"公司总结会 在公司总结会上，我那吞吞吐吐的表达不清的弱势，表现得淋漓尽致。反观同事的表述，层层深入，有条有据，每一句话都说到了点子上。就觉得自己除了技术，还有其他方面的能力需要进一步加强。 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:1:1","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"想开发一款跨平台的终端 在 mac 上有一款很好用的终端工具 Warp 但是 windows 上的好用的终端工具还非常的少，因此想自己使用 rust 开发一款终端工具，能够做到跨平台，使用简单等就好。 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:1:2","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"分享 像写代码一样写技术文章 go语言学习笔记 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:2:0","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"本周报分享每周所学所知所闻所感，时间范围是 2023-01-30 到 2023-02-05 会记录一些工作及生活上有意思的事情。 本周报每周日晚上发布，会同步到本人博客中 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["weekly"],"content":"见闻 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["weekly"],"content":"公司裁员 周四晚上准备下班，同事主动要求要和我一起下班回家，事出异常必有妖。下楼后，他和我说，他被裁员了，顿时我一懵逼。众所周知，我们公司是出了名的养老公司，今年居然裁员了，而且是裁了和我同一届不满一年的员工。这个事情，在我心里久久不能忘怀，生怕这柄达摩克利斯之剑，到我头上。 之后，仔细思考了一下，自己并不是在做公司的核心业务啊，可替换性非常大「需要时刻保持职业危机感」，而且职业发展空间不是很大。于是心里暗下决定，准备用一年的时间来转换自己的技术栈，争取在明年具备跳槽的资格。 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:1:1","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["weekly"],"content":"编程技术思考 这几年，技术进步不是很大，学习了go, rust, c等语言的基础语法，但是没有一些可以用于实战的项目来磨练我的技术。准备今年安排深入学习下go,rust,c并以项目进行驱动，学习下k8s和docker相关知识，并完善网络和linux相关知识栈。在学习语言的同时还需要完善编程模式，软件工程，算法等方面的知识，需要学习和做的事情很多。 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:1:2","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["weekly"],"content":"分享 一个程序员up主的笔记地址 混沌工程 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:2:0","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["思考"],"content":"Dear Ethan: 又到了充满期待的新的一年，过去的一年你过得还好吗？在往年的年终总结中，你会对即将到来的一年许下满满的期待。很明显，去年的你又是欠下满满债务的你。选择在你28岁的中点写一封信给自己，这更私人，但也更贴近你的内心。 ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:0:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["思考"],"content":"命途多舛，何以不甘 又一年的时间，你经历了不同的事情，遇到了不同的人，了解了不同的故事，现在轮到你说一说自己的故事了。也许都听过关于西西弗斯的故事，他的一生就是不断将巨石推到山顶，又不得不经受巨石滚落，再将石头推向山顶，这样一个荒诞的周而复始的故事。这也许，也是我们每一个人所需要经历的人生。 三月到五月的你，在小论文、毕业论文修改和实验中度过，那时的你，年轻气盛，因为一点小小的观点和老师争吵的面红耳赤。六月份经历了毕业的狂欢，阔别了昔日一起学习的良师益友，与好友约定毕业旅行，因囊中羞涩与疫情的封控而取消。急忙奔赴职场，结实新的朋友，重新投入到自我的升华之中。总的来说，去年的你，经历了人生中的两件大事：毕业和工作，再次完成学生到职场人身份的转变，其它的都是一地鸡毛。 这一年中失去的东西太多太多，任何一点细小的死亡与崩坏都会变得不可承受，这大概就是去年的一个缩影吧，巨石一次次的滚动，我们一次次的再上路。真的很想努力，但满满的无力感。这种无力感，年复一年，细细沉思，最早可追溯到2015年，那是我第一次深刻体会这种无力感。如今七年已过，你仍旧在与这种无力感继续搏斗着。 此前的每一个人生阶段—-初中，高中，大学，似乎总是被安排着走的，大的方向永远是一年比一年好。那份不甘于现实的热情，还能继续保持，也许正是因为不曾经历大的挫折。仔细回忆过往的人生，之前的你确实保持着点自我。那会儿呢，只需要考虑自己就已经足够了，家人永远是不断给予付出的那一方，所以那会儿做什么事都是那么天真吧！这份自我得益于你的少年意气，得益于家庭给你的支撑，也得益于时代的滚滚向前。但人生或命运从来就没有承诺过谁，总会往更好的方向发展。巨石总会滚落，而明天一早睁眼，我们依旧需要推着巨石往上。 ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:1:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["思考"],"content":"肩负起自己的责任 去年的你，每一天都在慌慌张张中度过，连家人都没能好好陪伴，也没有很好的意识到，父母的年纪已经到了颐养天年的时刻，我们需要无时不刻的关注着，陪伴着他们。而你每一天都在焦虑中挣扎，却无法鼓起勇气，让现在的你有所改观，因为你此刻内心是害怕的，害怕试错的代价太大，害怕失败，害怕被人嘲笑。可是，正如上面所说，人生或命运从来就没有承诺过谁，总会往更好的方向发展，所以今年的你，一定要鼓起勇气做出一点改变啦！ 我知道在过去的一年，你无数次打开B站，似乎想要寻找什么答案，可是刷了很久，焦虑一点没减少。事实一次次的告诉你，既然别人无法明确的告诉你，那你就要学会戴着镣铐和生活共舞，不是吗？毛姆在写《月亮与六便士》的时候，大概忘了在理想和现实中间还有责任。他没有告诉你站在路口，抬头是月亮，低头是捡硬币，责任在肩膀上压着，那你该往哪儿走。你唯一确定的是，你想负起这个责任。因为曾经家人的支持是你的底气，你今天，同样想成为家人的底气。 ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:2:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["思考"],"content":"所谓成长，接受自我 直到现在我才真正的意识到，所谓的成长就是认知的不断升级。只有当你明白这个道理，这个世界才开始真正的展开在你的眼前，原来以前认为错误的事情，原来也可以是对的「之前和老师争论的面红耳赤」。你不再为某一个你不认同的点去争论，慢慢的学会去理解别人，尊重别人，倾听大家的声音，不再自我，这已经是你最大的成长了。到了这个年纪才谈成长，这也许是一件过于奢侈的事情了。有很多很多的人，已经过早的品尝了世间的滋味。但对于刚入社会的我来说，考验才刚刚开始。成长不是随着年龄的增长，被社会打磨成一样的世故和圆滑，而是在生命的成熟中，仍有一颗纯真的童心和一颗善良的爱心。你想得到月亮，即使如此的平凡，不能起飞，也要努力的走着，跑着，伸手去够，去摘。即使经历过种种不顺，还是会有好事发生，会有新的缘分，新的身份，新的挑战，我不认输，你也不要，好吗？ ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:3:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["思考"],"content":"寄语未来 2023年，愿你在不平和焦虑的时候，能记起你的初心和梦想，然后大踏步的坚持走向明天！！！ ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:4:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["读后感"],"content":"务实的哲学 团队信任对于创造力和协作至关重要，关键时刻信任的破坏几乎无法修复 提供选择，别找借口– 小黄鸭编程 破窗理论– 不要因为一些危急的事情，造成附加伤害，尽可能控制软件的熵 人们都觉得，加入一个推进中的成功项目更容易一些（煮石头汤的故事） 永远审视项目，不要做温水青蛙，先养成仔细观察周围环境的习惯，然后再项目中这样做 知识和经验是你最重要的资产，但是它们是时效资产，学习新事物的能力是你最重要的战略资产。 知识组合： 定期投资–安排一个固定的时间和地点学习 每年学习一门新语言 每月读一本技术书 读非技术书 上课– 了解公司之外的人都在做什么 尝试不同的环境 与时俱进–关心最新技术的进展 想法的交叉是很重要的 批判性思维–批判性思考独到的和听到的东西 多样化– 熟悉的技能越多越好 风险管理–不同技术在高风险高回报到低风险低回报区间均匀分布，不要把技术鸡蛋放在一个篮子里 低买高卖–在一项新兴技术流行之前就开始学习，不过这是押宝 重新评估调整–不断刷新自己的知识库 批判性思维 五次为什么 谁从中收益 有什么背景 什么时候在哪里工作可以工作起来 为什么是这个问题 写一个大纲， 问自己：这是否用正确的方式表达了我想表达的东西，以及现在是表达这个东西的好时机吗？ ","date":"2023-01-02","objectID":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/:1:0","tags":["成长","笔记","反思","读后感"],"title":"读《程序员修炼之道》","uri":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/"},{"categories":["读后感"],"content":"务实的方法 ","date":"2023-01-02","objectID":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/:2:0","tags":["成长","笔记","反思","读后感"],"title":"读《程序员修炼之道》","uri":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/"},{"categories":["读后感"],"content":"ETC（easy to change） 核心知道思想 DRY(Don’t repeat yourself) 正交性 良好设计中，数据库相关代码应该和用户界面保持正交， 当系统的组件相互之间高度依赖时，就没有局部修理这回事。 ","date":"2023-01-02","objectID":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/:2:1","tags":["成长","笔记","反思","读后感"],"title":"读《程序员修炼之道》","uri":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/"},{"categories":["weekly"],"content":"本期主要记录自己在最近一周的所见所闻所思。尤其是自己对未来职业生涯的未知。 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"关于个人的发展 入司培训在这周已经如火如荼的展开了。这也标志着我正式踏入了网络安全行业，我是以开发工程师的身份进入的，但这确实我喜欢的一个特种行业。在安全行业中，懂开发的安全工程师是一个非常稀少的人群，这也是我接下来发展的方向。 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"最近的焦虑 最近十分的焦虑，一直在为自己之后的发展而发愁，这可能是我很自卑的缘故吧！于是我在B站大学收集了关于自己想学的许多的课程。在这里我进行分享下我收集的课程列表： ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:2:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"编程相关: C++教程：C++ Primer Plus(第六版)教程 算法与数据结构教程 编译原理（哈工大） ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:2:1","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"深度学习相关: ETH机器学习 2022NJUNLP夏令营 统计学习方法·第2版 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:2:2","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"网络安全相关: 最新Kail渗透测试安全工程师入门就业课程 SRC漏洞挖掘教程 渗透测试之皮卡丘靶场——Web从入门到放弃 我也将会在接下来的7，8，9月份中，制定严格的计划来完成一下学习和自我提升计划。计划如下： 7，8月份完成： C++教程：C++ Primer Plus 统计学习方法：第2版 SRC漏洞挖掘教程 9，10月份完成： 算法与数据结构教程 渗透测试之皮卡丘靶场——Web从入门到放弃 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:2:3","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"关于代码和技术 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:3:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"推荐化RSS 这个项目是我想利用项目来提升自己的技术。这个项目我是要带两个学弟一起弄，但是最近我发现沟通成本真的好大啊！可能是因为我们并没有项目合作的经验，大家都是单打独斗出来的，对这个产品不敢大胆的自定义。 这种感觉真的很熟悉，像是突然回到了，大学的时候和思彤一起想做一个相册web软件一样的感觉，最后，这个项目因为合作问题而难产。 这些经历，从现在的角度看来，无不是因为我的退缩和畏难的性格特点导致的。细想我走到今天真的很多决定都是因为我的胆小害怕导致的。这几天的培训也讲了相关的问题，我觉得我是一个固定思维大于发展思维的人。自己很想发展但是由于各种固定思维的限制，从而不敢大胆的迈出自己的脚步。这几天的课，给我的启示很多，既然今天的我已经走入了一个中等偏上的平台，我就应该利用好这个平台，努力完成属于自己的蜕变。 回到项目的问题，我觉得我可能是对学弟抱有了过高的期待，导致他们对项目丧失了主人翁思维。我应该自己先把这个软件做到一定的程度，之后需要加功能和改版的时候，可以带着他们一起改动，之后可以慢慢的培养他们的主人翁思维，这样的合作可能会更好。 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:3:1","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"给自己的话 每天需要抱有感恩的心，对这个世界和人需要有敬畏。 在人面前交流沟通，不需要紧张，大家都是公平的，只是表达自我而已，又没做什么对不起别人的事情。 要善于掩饰自己，不要让自己的菱角刺到朋友，使他成为了敌人。 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:4:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["防失业"],"content":"初试 - 文件变化后 server 自动重启 本源码系列是基于 Django4.0 的源码，可以自行到django 官方下载。 在此之前，不妨先了解下 django 是如何做到自动重启的 ","date":"2022-06-28","objectID":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/:1:0","tags":["笔记","技术","源码"],"title":"Django源码系列：文件变化后server自动重启机制","uri":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/"},{"categories":["防失业"],"content":"开始 django 使用 runserver 命令的时候，会启动俩个进程。 runserver 主要调用了 django/utils/autoreload.py 下 main 方法。 至于为何到这里的，我们这里不作详细的赘述，后面篇章会进行说明。 主线程通过 os.stat 方法获取文件最后的修改时间进行比较，继而重新启动 django 服务（也就是子进程）。 大概每秒监控一次。 # django/utils/autoreload.py 的 reloader_thread 方法 def reloader_thread(): ... # 监听文件变化 # -- Start # 这里主要使用了 `pyinotify` 模块，因为目前可能暂时导入不成功，使用 else 块代码 # USE_INOTIFY 该值为 False if USE_INOTIFY: fn = inotify_code_changed else: fn = code_changed # -- End while RUN_RELOADER: change = fn() if change == FILE_MODIFIED: sys.exit(3) # force reload elif change == I18N_MODIFIED: reset_translations() time.sleep(1) code_changed 根据每个文件的最后修改时间是否发生变更，则返回 True 达到重启的目的。 ","date":"2022-06-28","objectID":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/:1:1","tags":["笔记","技术","源码"],"title":"Django源码系列：文件变化后server自动重启机制","uri":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/"},{"categories":["防失业"],"content":"父子进程\u0026多线程 关于重启的代码在 python_reloader 函数内 # django/utils/autoreload.py def restart_with_reloader(): # 在这里开始设置环境变量为true new_environ = {**os.environ, DJANGO_AUTORELOAD_ENV: \"true\"} args = get_child_arguments() #获取执行的命令参数 # 重启命令在这里开始生效 while True: p = subprocess.run(args, env=new_environ, close_fds=False) if p.returncode != 3: return p.returncode def run_with_reloader(main_func, *args, **kwargs): signal.signal(signal.SIGTERM, lambda *args: sys.exit(0)) # 刚开始 DJANGO_AUTORELOAD_ENV是没有被设置为true的所以这里会进入到else里。 try: if os.environ.get(DJANGO_AUTORELOAD_ENV) == \"true\": reloader = get_reloader() logger.info( \"Watching for file changes with %s\", reloader.__class__.__name__ ) start_django(reloader, main_func, *args, **kwargs) # 开启django服务线程 else: exit_code = restart_with_reloader() sys.exit(exit_code) # 0为正常退出，其他的会抛出相关的错误 except KeyboardInterrupt: pass 程序启动，因为没有 RUN_MAIN 变量，所以走的 else 语句块。 颇为有趣的是，restart_with_reloader 函数中使用 subprocess.run 方法执行了启动程序的命令（ e.g：python3 manage.py runserver ），此刻 RUN_MAIN 的值为 True ，接着执行 _thread.start_new_thread(main_func, args, kwargs) 开启新线程，意味着启动了 django 服务。 如果子进程不退出，则停留在 run 方法这里（进行请求处理），如果子进程退出，退出码不是 3，while 则被终结。反之就继续循环，重新创建子进程。 ","date":"2022-06-28","objectID":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/:1:2","tags":["笔记","技术","源码"],"title":"Django源码系列：文件变化后server自动重启机制","uri":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/"},{"categories":["防失业"],"content":"总结 以上就是 django 检测文件修改而达到重启服务的实现流程。 结合 subprocess.run 和 环境变量 创建俩个进程。主进程负责监控子进程和重启子进程。 子进程下通过开启一个新线程（也就是 django 服务）。主线程监控文件变化，如果变化则通过 sys.exit(3) 来退出子进程，父进程获取到退出码不是 3 则继续循环创建子进程，反之则退出整个程序。 好，到这里。我们勇敢的迈出了第一步，我们继续下一个环节！！！ ヾ(◍°∇°◍)ﾉﾞ ","date":"2022-06-28","objectID":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/:1:3","tags":["笔记","技术","源码"],"title":"Django源码系列：文件变化后server自动重启机制","uri":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/"},{"categories":["思考"],"content":"从认识到双向链接开始我先使用了 obsidian,然而对于我这种懒癌晚期的人来说，需要结构化的记录，真的不太适合我「取一个好听的名字真的太难了」。当然有一说一，双链这个观点真的是太妙了。 现在的我已经全面转向了 logseq 来进行笔记记录，不得不说这种支持自定义代码的笔记真的不错「虽然我到目前为止使用最多的是高级查询和TODO这两个功能，记录笔记的话只是零星记录了几句话，并没有详细的记录或者输出一些东西。」。在 logseq 中是以日期为主线的，这免去了我对要写的内容的抽象主题的负担。 ","date":"2022-06-16","objectID":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/:0:0","tags":["成长","反思","思考"],"title":"关于周报这种小事","uri":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/"},{"categories":["思考"],"content":"工作日报周报 首先对任务进行分类，在学习了 Logseq 的高级查询语法并了解其能力之后，我决定使用#tag这种形式来组织个人任务和工作任务，属于工作任务的会标记上#work标签，个人任务就不进行标签。 首先就是工作，这个是大块内容，我目前使用 logseq 生成日报\u0026周报，用于之后提交到绩效评估系统中。 ","date":"2022-06-16","objectID":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/:1:0","tags":["成长","反思","思考"],"title":"关于周报这种小事","uri":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/"},{"categories":["思考"],"content":"日报/周报代码 日报和周报代码上只有 inputs[:yesterday]更改成 inputs[:7d]即可。 #+BEGIN_QUERY { :title \"查询昨天完成的任务\" :query [:find (pull ?b [*]) :in $ ?start ?end :where [?b :block/marker ?m] [?b :block/page ?p] [?p :page/journal? true] [?p :page/journal-day ?d] [(\u003e= ?d ?start)] [(\u003c= ?d ?end)] [?b :block/path-refs [:block/name \"work\"]] [(= \"DONE\" ?m)] ] :inputs [:yesterday :today] } #+END_QUERY 效果图如下： ","date":"2022-06-16","objectID":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/:1:1","tags":["成长","反思","思考"],"title":"关于周报这种小事","uri":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/"},{"categories":["成长"],"content":"在重听李沐老师的《Resnet 论文精读》这一课的时候，ps:「之前没有好好读，:\u003e)羞耻」。在讲到双栏论文中第一页的第二栏最上面，这个位置在学术界是非常重要的。提到了 Randy Pausch 教授在图形学开创了这一风格的写法，然后提到了他的最后一课「深刻印象」。 于是我从 cmu 网站中找到了当年演讲的材料，并完整的看了视频，这份笔记是 Randy 的人生经验和建议的抄录。 ","date":"2022-05-29","objectID":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/:0:0","tags":["成长","思考","人生建议"],"title":"Randy Pausch 教授的最后一课","uri":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/"},{"categories":["成长"],"content":"人生经验 Have something to bring to the table, because that will make you more welcom. 你必须要有一些真本领，这样可以让你更受欢迎。 You’ve got to get the fundamentals down because otherwise the fancy stuff isn’t going to work. 你必须练好基本功，否则后面的事情都不会发生。 That was a bit of a setback. But remember, the brick walls are there for a reason. The brick walls are not there to keep us out. The brick walls are there to give us a chance to show how badly we want something. Becuase the brick walls are there to stop the people who don’t want it badly enough. They’re there to stop the other people. Remember brick walls let us show our dedication. They are there to separate us from the people who don’t really want to achieve their childhood dreams. 你总会遇到挫折。但是记住，它们的出现不是没有原因的。砖墙并不是为了挡住我们。它在那里，只是为了测试，我们的决心到底有多迫切。它在那里挡住那些没有强烈决心的人。它不让那些人通过。记住，砖墙的存在是为了显示我们自己付出的决心。它使得我们，同那些并不真的想实现梦想的人得以区分。 ","date":"2022-05-29","objectID":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/:1:0","tags":["成长","思考","人生建议"],"title":"Randy Pausch 教授的最后一课","uri":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/"},{"categories":["成长"],"content":"为人处世的建议 helping others. 帮助他人。 never lose the childlike wonder. It’s what drives us. 永远不要失去好奇心，它是人类前进的动力。 Loyalty is a two way street. 诚以待人，这样别人也会忠实的对待你。 Never give up. 永远不要放弃 You can’t get there alone. People have to help you. You get people to help you by telling the truth. 你不能单打独斗，必须有人来帮你。只要你讲真话，就会有人来帮你。 Apologize when you screw up and focus on other people, not on yourself. 当你把事情搞砸，首先要向别人道歉，首先关心他们的损失，而不是你自己的损失。 When you do the right thing, good stuff has a way of happening. 如果你做了正确的事，好的结果自然会发生。 Get a feedback loop and listen to it. 注意倾听反馈。 Show gratitude. 感恩 Don’t complain. Just work harder. 不要抱怨，而要加倍努力。 Be good at something, it makes you valuable. 要有一技之长，它使你有价值。 Work hard. 努力再努力。 Find the best in everybody. 注意发现他人的优点。 Be prepared. Luck is truly where preparation meets opportunity. 做好准备。所谓幸运，真的是机会和准备的结合。 ","date":"2022-05-29","objectID":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/:2:0","tags":["成长","思考","人生建议"],"title":"Randy Pausch 教授的最后一课","uri":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/"},{"categories":["技术"],"content":"本文介绍 Tranformer 的代码。 ","date":"2022-05-28","objectID":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:0","tags":["技术","深度学习","笔记","源码阅读"],"title":"transformer源码阅读","uri":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["技术"],"content":"模型结构 Encoder 将输入序列$(x_{1},\\cdots,x_{n})$ 映射成一个连续的序列$z = (z_{1},\\cdots,z_{n})$。而 Decoder 根据$z$来解码得到输出序列$(y_{1},\\cdots,y_{m})$。Decoder 是自回归的(auto-regressive)–它会把前一个时刻的输出作为当前时刻的输入。Encoder-Decoder 结构模型的代码如下： class EncoderDecoder(nn.Module): \"\"\" 标准的Encoder-Decoder架构。 \"\"\" def __init__(self, encoder, decoder, src_embed, tgt_embed, generator): super(EncoderDecoder,self).__init__() self.encoder = encoder self.decoder = decoder # 源语言和目标语言的embedding self.src_embed = src_embed self.tgt_embed = tgt_embed # generator主要是根据Decoder的隐状态输出当前时刻的词(单个词) # 基本的实现就是隐状态输入一个全连接层，然后接一个softmax变成概率 self.generator = generator def forward(self, src, tgt, src_mask, tgt_mask): # 首先调用encode方法对输入进行编码，然后调用decode方法进行解码 return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask) def encode(self, src, src_mask): # 调用self.encoder函数 return self.encoder(self.src_embed(src), src_mask) def decode(self, memory, src_mask, tgt, tgt_mask): # 调用self.decoder函数 注意⚠️：这里定义的memery是encoder的输出结果。 return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask) EncoderDecoder 定义了一种通用的 Encoder-Decoder 架构，具体的 Encoder、Decoder、src_embed、target_embed 和 generator 都是构造函数传入的参数。这样我们做实验更换不同的组件就会更加方便。 class Generator(nn.Module): def __init__(self, d_model, vocab): super(Generator, self).__init__() # d_model是Decoder输出的大小，vocab是词典的大小 self.proj = nn.Linear(d_model, vocab) def forward(self, x): return F.log_softmax(self.proj(x), dim=-1) 注意 ⚠️：Generator 返回的是 softmax 的 log 值。在 pytorch 中为了计算交叉熵损失，有两种方法。第一种方法就是 nn.CrossEntropyLoss(),一种是使用 NLLLoss()。第一种方法更加容易懂，但是在很多开源代码里第二种更常见。 CrossEntropyLoss: criterion = nn.CrossEntropyLoss() x = torch.randn(1,5) # 服从0-1的正太分布。 y = torch.empty(1, dtype = torch.long).random_(5) loss = criterion(x,y) 比如上面的代码，假设是 5 分类问题，x表示模型的输出 logits(batch=1)，而 y 是真实分类的下标(0-4)。实际的计算过程为：$loss = -\\sum^{5}{i=1}y{i}log(softmax(x_{i}))$。 NLLLoss(Negative Log Likelihood Loss)是计算负 log 似然损失。它输入的 x 是 log_softmax 之后的结果（长度为 5 的数组），y 是真实分类（0-4），输出就是 x[y]。因此代码为： m = F.log_softmax(x, dim=1) criterion = nn.NLLLoss() x = torch.randn(1, 5) y = torch.empty(1, dtype = torch.long).random_(5) loss = criterion(m(x), y) Transformer 模型也是遵循上面的架构，只不过它的 Encoder 是 N(6)个 EncoderLayer 组成，每个 EncoderLayer 包含一个 Self-Attention SubLayer 层和一个全连接 SubLayer 层。而它的 Decoder 也是 N(6)个 DecoderLayer 组成，每个 DecoderLayer 包含一个 Self-Attention SubLayer 层、Attention SubLayer 层和全连接 SubLayer 层。如下图所示。 ","date":"2022-05-28","objectID":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:1:0","tags":["技术","深度学习","笔记","源码阅读"],"title":"transformer源码阅读","uri":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["技术"],"content":"Encoder 和 Decoder Stack 前面说了 Encoder 和 Decoder 都是由 N 个相同结构的 Layer 堆积(stack)而成。因此我们首先定义 clones 函数，用于克隆相同的 SubLayer。 def clones(module, N): # 克隆N个完全相同的SubLayer，使用了copy.deepcopy return nn.ModuleList([copy.deepcopy(module) for _ in range(N)]) 这里使用了 nn.ModuleList, ModuleList 就像一个普通的 Python 的 List，我们可以使用下标来访问它，它的好处是传入的 ModuleList 的所有 Module 都会注册的 PyTorch 里，这样 Optimizer 就能找到这里面的参数，从而能够用梯度下降更新这些参数。但是 nn.ModuleList 并不是 Module（的子类），因此它没有 forward 等方法，我们通常把它放到某个 Module 里。接下来定义 Encoder: class Encoder(nn.Module): # Encoder是N个EncoderLayer的stack def __init__(self, layer, N): super(Encoder, self).__init__() # layer是一个SubLayer，我们clone N个 self.layers = clones(layer, N) # 再加一个LayerNorm层 self.norm = LayerNorm(layer.size) def forward(self, x, mask): # 逐层进行处理 for layer in self.layers: x = layer(x, mask) # 最后进行LayerNorm return self.norm(x) Encoder 就是 N 个 SubLayer 的 stack，最后加上一个 LayerNorm。我们来看 LayerNorm: class LayerNorm(nn.Module): def __init__(self, features, eps=1e-6): super(LayerNorm, self).__init__() self.a_2 = nn.Parameter(torch.ones(features)) self.b_2. = nn.Parameter(torch.zeros(feagures)) self.eps = eps def forward(self, x): mean = x.mean(-1, keepdim = True) std = x.std(-1, keepdim = True) return self.a_2 * (x - mean)/(std+self.eps) + self.b_2 LayerNorm：假设数据为[batch_size, unit, 1, features]，这里是对整个样本进行 normalization。这里的 Layer Normalization 不是 Batch Normalization。 x -\u003e attention(x) -\u003e x+self-attention(x)[残差] -\u003e layernorm(x+self-attention(x)) =\u003e y y -\u003e dense(y) -\u003e y+dense(y) -\u003e layernorm(y+dense(y)) =\u003e z(输入下一层) 这里稍微做了一点修改， 在 self-attention 和 dense 之后加了一个 dropout 层。另一个不同支持就是把 layernorm 层放到前面了。这里的模型为： x -\u003e layernorm(x) -\u003e attention(layernorm(x)) -\u003e a + attention(layernorm(x)) =\u003e y y -\u003e layernorm(y) -\u003e dense(layernorm(y)) -\u003e y+dense(layernorm(y)) 原始论文的 layernorm 放在最后；而这里把它放在最前面并且在 Encoder 的最后在加了一个 layernorm。这里的实现和论文的实现基本是一致的，只是给最底层的输入 x 多做了一个 LayerNorm，而原始论文是没有的。下面是 Encoder 中的 forward 方法，这样比读者可能会比较清楚为什么 N 个 EncoderLayer 处理完成后还需要一个 LayerNorm。 def forward(self, x, mask): for layer in self.layers: x = layer(x, mask) return self.norm(x) 不管是 Self-Attention 还是全连接层，都首先是 LayerNorm，然后是 Self-Attention/Dense，然后是 Dropout，最好是残差连接。 class SublayerConnection(nn.Module): \"\"\" LayerNorm+sublayer(Self-Attention/Dense) + dropout + 残差连接 为了简单，把LayerNorm放到了前面，这和原始论文稍有不同，原始论文LayerNorm在最后。 \"\"\" def __init__(self, size, dropout): supper(SublayerConnection, self).__init__() self.norm = LayerNorm(size) self.dropout = nn.Droupout(dropout) def forward(self, x, sublayer): # sublayer是传入的参数,之后进行残差连接 return x+self.dropout(sublayer(self.norm(x))) Self-Attention 或者 Dense 并不在这里进行构造，而是放在了 EncoderLayer 里，在 forward 的时候由 EncoderLayer 传入。这样的好处是更加通用，比如 Decoder 也是类似的需要在 Self-Attention、Attention 或者 Dense 前面加上 LayerNorm 和 Dropout 以及残差连接，我们就可以复用代码。但是这里要求传入的 sublayer 可以使用一个参数来调用的函数。 class EncoderLayer(nn.Module): # EncoderLayer由self-attn和feed_forward组成 def __init__(self, size, self_attn, feed_forward, dropout): super(EncoderLayer, self).__init__() self.size = size self.self_attn = self_attn self.feed_forward = feed_forward self.sublayer = clones(SublayerConnection(size, dropout), 2) def forward(self, x, mask): x = self.sublayer[0](x, lambda x:self.self_attn(x,x,x,mask)) return self.sublayer[1](x, self.feed_forward) 为了复用，这里的 self_attn 层和 feed_forward 层也是传入的参数，这里只构造两个 SublayerConnection。forward 调用 sublayer0的call方法，最终会调到它的 forward 方法，而这个方法需要两个参数，一个是输入 Tensor， 一个是一个 callable, 并且这个 callable 可以用一个参数来调用。而 self_attn 函数需要 4 个参数（Query 的输入，key 的输入，Value 的输入和 Mask），因此这里我们使用 lambda 的技巧把它变成一个参数 x 的函数(mask 可以堪称已知的数)。因为 lambda 的形参也叫 x. Decoder class Decoder(nn.Module): def __init__(self, layer, N): super(Decoder, self).__init__() self.layers = clones(layer, N) self.norm = LayerNorm(layer.size) def forward(self, x, memory, src_mask, tgt_mask): for layer in self.layers: x = layer(x, memory, src_mask, tgt_mask) return self.norm(x) Decoder 也是 N 个 DecoderLayer 的 stack，参数 layer 是 DecoderLayer，它也是一个 callable，最终call会调用 DecoderLayer.forward 方法，这个方法需要 4 个参数，输入 x, Encoder 层的输出 memory, 输入 Encoder 的 Mask(src_mask)和输入 Decoder 的 ","date":"2022-05-28","objectID":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:2:0","tags":["技术","深度学习","笔记","源码阅读"],"title":"transformer源码阅读","uri":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["技术"],"content":"MultiHeadedAttention 多头注意力机制 Attention(包括 Self-Attention 和普通的 Attention)可以堪称一个函数，它的输入是 Query，Key，Value 和 Mask，输出是一个 Tensor。其中输出是 Value 的加权平均，而权重来自 Query 和 Key 的计算。具体的计算如下图所示，计算公式为：$$Attention(Q,K,V) = softmax(\\frac{QK^{T}}{\\sqrt{d_{k}}})V$$ 代码为： def attention(query, key, value, mask=None,dropout=None): d_k = query.size(-1) scores = torch.matmul(query,key.transpose(-2,-1))/math.sqrt(d_k) if mask is not None: scores = scores.mask_fill(mask==0,-1e9) p_attn = F.softmax(scores, dim=-1) if dropout is not None: p_attn = dropout(p_attn) return torch.matmul(p_attn,value),p_attn 这里主要的疑问是在score.mask_fill，主要用于把 mask 是 0 的变成一个很小的数，这样后面经过 softmax 之后的概率就很接近零（但是理论上还是用了很少一点点未来的信息）。 之前介绍过，对于每一个 Head，都是用三个矩阵$W^{Q}$，$W^{K}$，$W^{V}$把输入转换成 Q，K 和 V。然后分别用每一个 Head 进行 Self- Attention 的计算，最后把 N 个 Head 的输出拼接起来，最后用一个矩阵$W^{O}$把输出压缩一下。具体计算框架为： 代码如下： class MultiHeadAttention(nn.Module): def __init__(self, h, d_model, dropout=0.1): super(MultiHeadAttention, self).__init__() assert d_model % h == 0 self.d_k = d_model // h # 这里是整除 self.h = h self.linears = clones(nn.Linear(d_model,d_k),4) self.attn = None self.dropout = nn.Dropout(p=dropout) def foward(self, query, key, value, mask=None): if mask is not None: # 所有h个head的mask都是相同的 mask = mask.unsqueeze(1) nbatches = query.size(0) # 1) 首先使用线性变换，然后把d_model分配给h个Head，每个head为d_k=d_model/h query, key, value = [l(x).view(nbatches,-1,self.h,self.d_k).transpose(1,2) for l,x in zip(self.linears,(query, key, value))] # 2) 使用attention函数计算 x, self.attn = attention(query, key, value, mask=mask,dropout = self.dropout) # 3） x = x.transpose(1,2).contiguous().view(nbatches, -1,self.h*self.d_k) return self.linears[-1](x) 我们首先来看构造函数， 这里 d_model(512)是 Multi-Head 的输出大小，因为有 h(8)个 head， 因此每个 head 的 d_k=512/8=64。接着我们构造 4 个(d_model $*$ d_model)的矩阵，后面我们会看到它的用处。最后是构造一个 Dropout 层。 然后我们来看 forward 方法。输入的 mask 是（batch,1,time）的，因为每个 head 的 mask 都是一样的，所以先用 unsqueeze(1)变成(batch,1,1,time)，mask 我们前面已经分析过了。 接下来就是根据输入的 query, key, value 计算变换后的 Multi-Head 的 query, key 和 value。zip(self.linears, (query,key,value))是把(self.linear[0], self.linear[1], self.linear[2])和(query, key, value)放在一起遍历。我们可以只看一个self.linear[0] (query)。根据构造函数的定义，self.linear[0]是一个[512,512]的矩阵，而query是(batch, time, 512)，相乘之后得到的新 query 还是 512 维的向量，然后用 view 把它变成(batch, time, 8, 64)。然后 transpose 成(batch, 8, time, 64)，这是 attention 函数要求的 shape。分别对 8 个 Head，每个 Head 的 Query 都是 64 维。最后使用self.linear[-1]对x进行线性变换，self.linear[-1]是[512, 512]的，因此最终的输出还是(batch, time, 512)。 ","date":"2022-05-28","objectID":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:3:0","tags":["技术","深度学习","笔记","源码阅读"],"title":"transformer源码阅读","uri":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["思考"],"content":"这一段时间我也一直在思考，毕业之后的发展。读了许多大佬写的博客，想着能够从中汲取一些经验和启发。发现大家都有一个共性就是善于总结和对自己的职业生涯进行了一定的规划，他们清楚的了解自己的定位和未来想要得到什么。我一直坚信花时间来整理状态，是一件很值得投资的事情。这篇文章也相当于研究生生涯总结和职业生涯的开篇吧！ 毕业前的时光算得上是踏上职场前最后的悠闲。尽管对未来充满了希望，与此同时，我的内心也充斥着彷徨。害怕在未来几年一无所成，害怕自己达不到自己所期待的那种境界。每年设定目标，然而能够完成的却寥寥无几。才有了现在对未来的迷茫，心中一腔热血却像苍蝇一样，漫无目的。这可能也是普通人和大佬之间的区别吧！阅读过大佬的文章后，有下面的启示。 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:0:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["思考"],"content":"别多想，多实践 你思考的 90%的问题，至少 1000 年前，先哲们都给了答案。 剩下的 10%，300 年前的哲学家，思想家一定给出了答案。 绝对不存在你思考的问题，历史上的思想家没有给出答案。所以大多数的时候，没看书之前，你的思考，是徒劳的。 大多数时候，我们所思考的问题，前人都已经思考过了。我们需要做的是，踏踏实实的沉下心来，进行学习即可。我们总在思考未来应该如何做才能快速的成长，追求完成一件事情的形式。殊不知未来正是由无数个当下的事情组成的。与其担心未来，还不如沉下心来把当下的事情做到极致，未来一定会出现在你的眼前。 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:1:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["思考"],"content":"尽早规划（长线思维） 怎么过一天，就怎么过一生，如果认为明天或一年之后会有所改变，那么今天的自己是一年前希望看到的自己么。 随着时间的推移，资产（你认为有价值的一切）变得更有价值还是廉价 把每一个场景都看成投资场景，每一个行为当作投资行为，重视它对现在及将来的影响 咱们中国有一个不变的传统就是“五年规划”，国家尚且如此，何况人？所以我们也要及早的对自己进行一个五年规划，这个规划应该是方向性的，不是细节的。细节应当是每年每季度每月具体去完成以达到五年规划中的目标。 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:2:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["思考"],"content":"注重输出 只是看书或者视频，容易造成已经理解了某个知识点的错觉，短期记忆未经加固，很快就会「挥发」 无输出不输入，输出的方式可以是文章或者视频或者闲聊，经过强化后的内容更容易进入长期记忆 输出的过程会联结之前的积累，让知识更扎实，输出过程也会更流畅，输入和输出的比例可以控制在 3:7 在知识库系统的过程中，我们往往过于完美主义，想把知识系统工具一次性构建完整，然后把大量的时间都放在了工具的搭建中，折腾了很多中工具：notion, obsidian, logseq 等。我个人认为，工具是在自己不断的使用的过程中完善的，知识库也是一样，首先我们要有输出，之后在慢慢的进行调整，最后会实现一个理想中适合自己的知识系统的。我在这里建议放弃完美主义，在实践中不断的调整自己调整工具。还有一个就是逃离算法推荐吧，拥抱内容的多元化。 不要只停留在理论上，去实践，会发现更多的问题和挑战，也更有趣味，“what i cannot create, i do not understand”。 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:3:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["思考"],"content":"参考资料 工程师的成长 写在 28 岁边上 技术同学在业务中的成长 用未来的视角来看今天 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:4:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["技术"],"content":"工作中常需要连接着服务器，比如在深度学习训练模型的过程中，需要长时间连接着服务器，在一段时间没有操作后，ssh 会自动断开。 为了解决这个问题，在网上找到一种配置方法，亲测很久都不会再断开了，在此记录： 众所周知，ssh 是用于与远程服务器建立加密通信通道的，因此配置涉及到服务器和客户端： 服务端 /etc/ssh/sshd_config +ClientAliveInterval 60 # 每60秒发送一个KeepAlive请求 +ClientAliveCountMax 15 # 总时间为：15*60， 15分钟没有操作，终端断开。 # 以下命令重启 sshd 服务 service sshd reload service sshd restart 客户端 ~/.ssh/config # 修改～/.ssh/config配置，对当前用户生效 # 这样配置通配所有服务端 Host * ServerAliveInterval 60 ","date":"2022-05-13","objectID":"/ssh%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/:0:0","tags":["技术","工具","ssh"],"title":"ssh自动断开修复方法","uri":"/ssh%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/"},{"categories":["技术"],"content":"参考文献 SSH 长时间不使用自动断开解决方案 ","date":"2022-05-13","objectID":"/ssh%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/:1:0","tags":["技术","工具","ssh"],"title":"ssh自动断开修复方法","uri":"/ssh%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/"},{"categories":null,"content":"关于我 长期从事⽹络安全与深度学习结合以及网络协议分析相关开发⼯作, 专注⾼速报⽂处理及 DPI 技术, 追求极致性能, 欣赏优雅简洁之美, 重视⽂档. ","date":"2022-01-01","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"成果 Zhou X, Hu Y, Liang W, et al. Variational LSTM enhanced anomaly detection for industrial big data[J]. IEEE Transactions on Industrial Informatics, 2020, 17(5): 3469-3477. Zhou X, Hu Y, Wu J, et al. Distribution Bias Aware Collaborative Generative Adversarial Network for Imbalanced Deep Learning in Industrial IoT[J]. IEEE Transactions on Industrial Informatics, 2022. Liang W, Hu Y, Zhou X, et al. Variational Few-Shot Learning for Microservice-Oriented Intrusion Detection in Distributed Industrial IoT[J]. IEEE Transactions on Industrial Informatics, 2022, 18(8): 5087-5095. ","date":"2022-01-01","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"}]