[{"categories":["技术"],"content":"01. 基础RAG（Simple RAG） ","date":"2025-06-18","objectID":"/%E5%9F%BA%E7%A1%80rag/:0:0","tags":["技术","RAG","笔记"],"title":"RAG系列-基础RAG（Simple RAG）","uri":"/%E5%9F%BA%E7%A1%80rag/"},{"categories":["技术"],"content":"方法简介 基础RAG（Retrieval-Augmented Generation）是最简单的检索增强生成方法。它通过向量化检索获取与用户查询最相关的文档片段，并将这些片段作为上下文输入给大语言模型进行答案生成。 ","date":"2025-06-18","objectID":"/%E5%9F%BA%E7%A1%80rag/:1:0","tags":["技术","RAG","笔记"],"title":"RAG系列-基础RAG（Simple RAG）","uri":"/%E5%9F%BA%E7%A1%80rag/"},{"categories":["技术"],"content":"核心代码 import fitz import os import numpy as np import json from openai import OpenAI def extract_text_from_pdf(pdf_path): \"\"\" Extracts text from a PDF file and prints the first `num_chars` characters. Args: pdf_path (str): Path to the PDF file. Returns: str: Extracted text from the PDF. \"\"\" # Open the PDF file mypdf = fitz.open(pdf_path) all_text = \"\" # Initialize an empty string to store the extracted text # Iterate through each page in the PDF for page_num in range(mypdf.page_count): page = mypdf[page_num] # Get the page text = page.get_text(\"text\") # Extract text from the page all_text += text # Append the extracted text to the all_text string return all_text # Return the extracted text def chunk_text(text, n, overlap): \"\"\" Chunks the given text into segments of n characters with overlap. Args: text (str): The text to be chunked. n (int): The number of characters in each chunk. overlap (int): The number of overlapping characters between chunks. Returns: List[str]: A list of text chunks. \"\"\" chunks = [] # Initialize an empty list to store the chunks # Loop through the text with a step size of (n - overlap) for i in range(0, len(text), n - overlap): # Append a chunk of text from index i to i + n to the chunks list chunks.append(text[i:i + n]) return chunks # Return the list of text chunks # Initialize the OpenAI client with the base URL and API key client = OpenAI( base_url=\"https://api.studio.nebius.com/v1/\", api_key=os.getenv(\"OPENAI_API_KEY\") # Retrieve the API key from environment variables ) def create_embeddings(text, model=\"BAAI/bge-en-icl\"): \"\"\" Creates embeddings for the given text using the specified OpenAI model. Args: text (str): The input text for which embeddings are to be created. model (str): The model to be used for creating embeddings. Default is \"BAAI/bge-en-icl\". Returns: dict: The response from the OpenAI API containing the embeddings. \"\"\" # Create embeddings for the input text using the specified model response = client.embeddings.create( model=model, input=text ) return response # Return the response containing the embeddings def cosine_similarity(vec1, vec2): \"\"\" Calculates the cosine similarity between two vectors. Args: vec1 (np.ndarray): The first vector. vec2 (np.ndarray): The second vector. Returns: float: The cosine similarity between the two vectors. \"\"\" # Compute the dot product of the two vectors and divide by the product of their norms return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)) def semantic_search(query, text_chunks, embeddings, k=5): \"\"\" Performs semantic search on the text chunks using the given query and embeddings. Args: query (str): The query for the semantic search. text_chunks (List[str]): A list of text chunks to search through. embeddings (List[dict]): A list of embeddings for the text chunks. k (int): The number of top relevant text chunks to return. Default is 5. Returns: List[str]: A list of the top k most relevant text chunks based on the query. \"\"\" # Create an embedding for the query query_embedding = create_embeddings(query).data[0].embedding similarity_scores = [] # Initialize a list to store similarity scores # Calculate similarity scores between the query embedding and each text chunk embedding for i, chunk_embedding in enumerate(embeddings): similarity_score = cosine_similarity(np.array(query_embedding), np.array(chunk_embedding.embedding)) similarity_scores.append((i, similarity_score)) # Append the index and similarity score # Sort the similarity scores in descending order similarity_scores.sort(key=lambda x: x[1], reverse=True) # Get the indices of the top k most similar text chunks top_indices = [index for index, _ in similarity_scores[:k]] # Return the top k most relevant text chunks return [text_chunks[index] for index in top_indices] def generate_response(system_prompt, user_message, model=\"meta-llama/Llama-3.2-3B-Instruct\"): \"\"\" Generates a response from the AI model based on the system prompt and user message. Args: system_prompt (str)","date":"2025-06-18","objectID":"/%E5%9F%BA%E7%A1%80rag/:2:0","tags":["技术","RAG","笔记"],"title":"RAG系列-基础RAG（Simple RAG）","uri":"/%E5%9F%BA%E7%A1%80rag/"},{"categories":["技术"],"content":"代码讲解 文档处理：使用PyMuPDF提取PDF文本，按字符数分块 嵌入生成：使用BAAI/bge-en-icl模型生成文本嵌入 语义搜索：计算查询与文档块的余弦相似度，返回最相关的k个片段 答案生成：将检索到的上下文与用户问题输入LLM生成答案 ","date":"2025-06-18","objectID":"/%E5%9F%BA%E7%A1%80rag/:3:0","tags":["技术","RAG","笔记"],"title":"RAG系列-基础RAG（Simple RAG）","uri":"/%E5%9F%BA%E7%A1%80rag/"},{"categories":["技术"],"content":"主要特点 实现简单，易于理解和扩展 使用余弦相似度进行语义检索 支持PDF文档处理 可配置的检索数量k ","date":"2025-06-18","objectID":"/%E5%9F%BA%E7%A1%80rag/:4:0","tags":["技术","RAG","笔记"],"title":"RAG系列-基础RAG（Simple RAG）","uri":"/%E5%9F%BA%E7%A1%80rag/"},{"categories":["技术"],"content":"使用场景 FAQ自动问答 小型企业知识库 结构化文档检索增强 基础文档问答系统 ","date":"2025-06-18","objectID":"/%E5%9F%BA%E7%A1%80rag/:5:0","tags":["技术","RAG","笔记"],"title":"RAG系列-基础RAG（Simple RAG）","uri":"/%E5%9F%BA%E7%A1%80rag/"},{"categories":["生活"],"content":"2024年回顾 ","date":"2025-01-01","objectID":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/:1:0","tags":["年度总结","AI","个人成长"],"title":"2025年展望","uri":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/"},{"categories":["生活"],"content":"1月-2月：安家落户 终于完成了人生中的一件大事 - 买房。拿到房产证的那一刻，我和妻子都感到无比欣喜。这个新家不仅是一个住所，更是我们对未来生活的美好期待。 ","date":"2025-01-01","objectID":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/:1:1","tags":["年度总结","AI","个人成长"],"title":"2025年展望","uri":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/"},{"categories":["生活"],"content":"3月-4月：平稳前行 这段时间主要是日常工作和还贷。虽然每个月能存下的钱不多，但生活依然充满欢乐。我们学会了在有限的预算中寻找生活的乐趣。 ","date":"2025-01-01","objectID":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/:1:2","tags":["年度总结","AI","个人成长"],"title":"2025年展望","uri":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/"},{"categories":["生活"],"content":"5月-6月：职场动荡 公司经历了裁员风波，虽然我幸免于难，但这次事件让我对公司的未来产生了疑虑。这段时间充满了迷茫和不确定性，尝试了很多事情但进展不大。 ","date":"2025-01-01","objectID":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/:1:3","tags":["年度总结","AI","个人成长"],"title":"2025年展望","uri":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/"},{"categories":["生活"],"content":"7月-10月：装修新家 新房进入装修阶段，虽然经济压力较大，但每周回长沙监工的过程充满了期待和喜悦。看着新家一点点成型，所有的辛苦都值得。 ","date":"2025-01-01","objectID":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/:1:4","tags":["年度总结","AI","个人成长"],"title":"2025年展望","uri":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/"},{"categories":["生活"],"content":"11月-12月：健康与AI探索 体检发现患有桥本甲状腺炎，这让我开始更加关注身体健康。同时，AI技术的快速发展让我产生了强烈的危机感。经过深入思考和实践，我决定拥抱AI而不是恐惧它。 这段时间，我深入探索了多种AI工具： Cursor Windsurf（开通了Pro版） Cline Aider Zed AI 通过实践，我发现每种工具都有其独特优势，于是开始尝试多种工具结合使用。12月中旬，我开始利用AI接一些外包项目，主要目的有两个： 缓解经济压力 深入探索AI能力，提升工作效率 ","date":"2025-01-01","objectID":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/:1:5","tags":["年度总结","AI","个人成长"],"title":"2025年展望","uri":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/"},{"categories":["生活"],"content":"2025年展望 在新的一年里，我为自己设定了以下目标： AI SOP优化：总结出一套适合自己的AI使用流程和标准操作程序 产品开发：借助AI工具，完成第一个产品的MVP（最小可行产品） 全栈开发：开始探索全栈式开发，提升技术广度 AI辅助学习：建立高效的AI辅助学习体系，加速知识获取 事业基础：为未来的事业发展打下坚实基础 2025年将是充满挑战和机遇的一年。我相信，通过合理利用AI工具，持续学习和自我提升，我能够实现这些目标，为未来创造更多可能性。 “未来属于那些相信梦想之美的人。” - 埃莉诺·罗斯福 ","date":"2025-01-01","objectID":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/:2:0","tags":["年度总结","AI","个人成长"],"title":"2025年展望","uri":"/2025%E5%B9%B4%E5%B1%95%E6%9C%9B/"},{"categories":["编程"],"content":"最近，我有幸体验了windsurf编辑器的AI辅助编程功能。这款编辑器的编程体验令人印象深刻，在某些方面甚至超越了我使用过的其他主流编辑器。然而，经过一天的深入使用后，我发现它仍存在一些需要改进的地方。 最初，我期望AI能够完全接管代码编写工作，或者至少大幅减少我在低级编码任务上的时间投入，让我能够专注于更高层次的架构设计。然而，现实与期望存在差距。在持续使用过程中，我注意到AI的解决问题的能力会随着会话时间的延长而逐渐下降。 经过分析，我认为这可能与windsurf的架构设计有关。该编辑器的AI辅助功能基于agent模式开发，在使用过程中我频繁遇到响应错误，且这种错误会随着使用时间的增加而变得更加频繁。更令人困扰的是，有时AI虽然能够正确回答问题，却无法实际修改代码来解决问题。我推测这可能是windsurf中存在的一个bug，导致AI无法持续执行代码修改任务。 值得注意的是，AI辅助编程的核心能力并非来自其\"智能\"，而是源于其对代码的深度分析和理解能力。AI之所以能够快速解决问题，是因为它能够高效地分析代码之间的关联，理解代码的逻辑结构和生命周期。然而，随着会话的持续，这种分析和理解能力似乎会逐渐衰减，这可能是由于软件性能优化不足导致的。 要实现真正优雅的AI辅助编程，还需要在多个方面进行优化和改进。虽然短期内可能无法完全解决这些问题，但不可否认的是，AI辅助编程仍然是一个强大的工具。它能够帮助我们快速学习和掌握新的编程语言，显著提升学习效率和工作效能。相信随着技术的不断进步，这些问题终将得到解决，为开发者带来更优质的编程体验。 ","date":"2024-12-06","objectID":"/windsurf%E7%BC%96%E7%A0%81%E4%BD%93%E9%AA%8C/:0:0","tags":["成长","编程工具","代码人生","折腾"],"title":"windsurf编码体验","uri":"/windsurf%E7%BC%96%E7%A0%81%E4%BD%93%E9%AA%8C/"},{"categories":["经济观点"],"content":"今天读了付鹏先生在HSBC内部演讲的文稿，后面相继听了高善文先生的演讲。在阅读了高善文和付鹏关于中国经济形势的深刻分析后，我获得了对当前和未来经济趋势的更全面理解。 通过深入阅读高善文的分析，我深刻认识到经济转型和周期性压力是塑造中国经济未来的关键力量。经济转型引发的结构性变化是深远而持久的，它要求我们不断适应新的发展模式，比如从劳动密集型向技术密集型转变，从投资驱动向消费驱动转变。与此同时，周期性压力则在短期内对经济产生显著影响，如需求波动、市场信心变化等，这些都可能对我们的职业和财务状况产生直接或间接的影响。 这种理解使我意识到在不同的经济周期阶段，需要采取不同的应对策略。目前，我们的职业生涯将长期处于这个经济周期的尾声阶段，这意味着整体经济环境、就业环境以及收入增长潜力都不能与经济高速发展时期同日而语。为了适应这些变化，我们需要认真评估自己所在行业在经济转型中的位置，以及未来可能的发展趋势。如果行业前景黯淡，可能需要考虑转行或提升技能以适应新兴行业的需求。在经济增速放缓的背景下，我们也需要更加谨慎地管理个人财务，包括减少不必要的债务、增加储蓄和投资于相对稳定的资产。然后调整消费习惯，避免过度消费，尤其是在经济不确定性较高时期，理性消费变得更加重要。也是时候考虑要开启副业，增加职业以外的收入，以应对可能的经济波动。希望能够更好地应对经济转型和周期性压力带来的挑战，同时也为未来可能出现的新机遇做好准备。 作为普通人，我们需要建立更为全面和深入的经济理解，以便在不断变化的经济环境中做出明智的决策。这两篇文章为我未来的财务规划和职业发展提供了宝贵的指导。 ","date":"2024-12-03","objectID":"/%E8%AF%BB%E4%BB%98%E9%B9%8F%E5%92%8C%E9%AB%98%E5%96%84%E6%96%87%E5%AF%B9%E5%BD%93%E5%89%8D%E7%BB%8F%E6%B5%8E%E8%AF%84%E8%AE%BA/:0:0","tags":["成长","思考","经济观点"],"title":"读付鹏和高善文对当前经济评论","uri":"/%E8%AF%BB%E4%BB%98%E9%B9%8F%E5%92%8C%E9%AB%98%E5%96%84%E6%96%87%E5%AF%B9%E5%BD%93%E5%89%8D%E7%BB%8F%E6%B5%8E%E8%AF%84%E8%AE%BA/"},{"categories":["weekly"],"content":"由于明天要去团建，后天一大早就要赶火车回长沙。所以周报今天先完成。后面每周都会写下我对生活的思考。 ","date":"2024-11-14","objectID":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"2024年第46周, 患上桥本了","uri":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/"},{"categories":["weekly"],"content":"本周的生活概述 ： 周六，参加了公司组织的年度体检。今年我对去年发现的甲状腺结节问题尤为关注，特意增加了甲功三项B专项检查。体检过程中，医生还建议我增加两项指标检测：抗甲状腺球蛋白抗体(TG-Ab)和甲状腺过氧化物酶抗体(TPO-Ab)，用于诊断是否患有桥本甲状腺炎。当天下午，血液检查结果就可以通过小程序同步查看结果显示我的TG-Ab高达78.14(IU/ml 正常范围0-4.11), TPO-Ab高达28.6(IU/ml 正常范围0-5.63)。 这对我来说，就是暴击，无疑就已经宣判了我患桥本了。后面仔细想了想，我体检前一天晚上没怎么睡好，且前一阵子不是吃烧烤就是出去喝奶茶，加上从媳妇老家带过来的辣椒酱爱不释手，可能这两个指标飙升和自身的生活习惯有关。在阅读了和桥本相关的医学知识后，感觉我从此要和辣椒无缘了，我可是正宗的湖南人啊，没有辣椒我能活？媳妇还在一旁不停的讲风凉话。不过我媳妇，也就是讲讲，心理比谁都更加重视我的健康。才30岁的我，身体就已经开始下滑，这让我开始反思自己。在这之前，我从来认为吃饭不就是一项任务？随意吃一点就好。以为自己很年轻，有更多的事情比吃饭，睡觉更加重要。现在想想，我真的有点大错特错了，对于现在的我们来说，其实最重要的是照顾好身体，身体才是我们的本钱，没有本钱，怎么去实现自己的价值呢？ ","date":"2024-11-14","objectID":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"2024年第46周, 患上桥本了","uri":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/"},{"categories":["weekly"],"content":"成长与学习 ： 阅读完成《真需求》梁宁 阅读《亲密关系》罗兰.米勒 20% 阅读《桥本甲状腺炎90天治疗方案》20% ","date":"2024-11-14","objectID":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/:2:0","tags":["技术","周报","启示"],"title":"2024年第46周, 患上桥本了","uri":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/"},{"categories":["weekly"],"content":"健康与自我关爱 ： ","date":"2024-11-14","objectID":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/:3:0","tags":["技术","周报","启示"],"title":"2024年第46周, 患上桥本了","uri":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/"},{"categories":["weekly"],"content":"圆环闭合情况： 自从检查出桥本后，我基本每天早上半小时运动，中午半小时运动，晚饭后半小时运动，然后调整饮食，一个月后再去复查，看看指标有没有下降或好转的可能。 ","date":"2024-11-14","objectID":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/:3:1","tags":["技术","周报","启示"],"title":"2024年第46周, 患上桥本了","uri":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/"},{"categories":["weekly"],"content":"下周的计划 ： 下周准备回长沙，搞开荒，然后软装进场。终于房子装修告一段落了。诶，从买房到现在已经月光了一整年。希望月光的时间赶紧过去，然后尽自己最大的能力存钱。 ","date":"2024-11-14","objectID":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/:4:0","tags":["技术","周报","启示"],"title":"2024年第46周, 患上桥本了","uri":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/"},{"categories":["weekly"],"content":"乐趣与感恩 ： 从看到诊断结果到现在整整一周了，她每天坚决执行清淡饮食，督促我早睡早起，每天早上出门锻炼30分钟。在这里我非常感谢我媳妇在背后对我的支持。 ","date":"2024-11-14","objectID":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/:5:0","tags":["技术","周报","启示"],"title":"2024年第46周, 患上桥本了","uri":"/2024%E5%B9%B4%E7%AC%AC46%E5%91%A8/"},{"categories":["思考"],"content":"当下 本页记录当下我需要专注的事情。更新于2024/12/02 于中国武汉 ","date":"2024-11-14","objectID":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/:0:0","tags":["成长","反思","思考"],"title":"当下的事情","uri":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/"},{"categories":["思考"],"content":"生活 日常工作：练习专注，寻找目标感 项目稳步推进 测试同学的挑衅淡定对待，工作而已 业余生活：稳定作息，健康生活 坚持做饭 有节奏的作息，拒绝熬夜 运动健身：提高基础代谢 开始跑步，每周至少两次 继续羽毛球运动 ","date":"2024-11-14","objectID":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/:1:0","tags":["成长","反思","思考"],"title":"当下的事情","uri":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/"},{"categories":["思考"],"content":"学习 读书： 阅读《build a large language model from scratch》 60% 阅读《真需求》梁宁 阅读《亲密关系》罗兰.米勒 20% 阅读《桥本甲状腺炎90天治疗方案》20% 阅读《learning-ebpf》5% 技术： 学习深度包解析技术 学习TCP协议相关知识 学习rust相关知识 写作： 提升写作方面的能力 ","date":"2024-11-14","objectID":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/:2:0","tags":["成长","反思","思考"],"title":"当下的事情","uri":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/"},{"categories":["思考"],"content":"项目 流量采集器 ","date":"2024-11-14","objectID":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/:3:0","tags":["成长","反思","思考"],"title":"当下的事情","uri":"/%E5%BD%93%E4%B8%8B%E4%B8%93%E6%B3%A8/"},{"categories":["工具"],"content":"This message is used to verify that this feed (feedId:71916462721158158) belongs to me (userId:45764741539537920). Join me in enjoying the next generation information browser https://follow.is. ","date":"2024-10-24","objectID":"/%E8%AE%A4%E8%AF%81follow%E8%AE%A2%E9%98%85%E6%BA%90/:0:0","tags":["工具"],"title":"认证订阅","uri":"/%E8%AE%A4%E8%AF%81follow%E8%AE%A2%E9%98%85%E6%BA%90/"},{"categories":["weekly"],"content":"本周报分享每周所学所知所闻所感，时间范围是 2023-02-13 到 2023-02-19 会记录一些工作及生活上有意思的事情。 本周报每周日晚上发布，会同步到本人博客中 ","date":"2023-02-19","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"2023年第7周, 新的旅途","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/"},{"categories":["weekly"],"content":"见闻 ","date":"2023-02-19","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"2023年第7周, 新的旅途","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/"},{"categories":["weekly"],"content":"为个人开发者实现了一套集成化的收费方案 最近一周在捣腾 RSS 订阅软件的事情，发现市面上可以主动发现独立博客，并可以订阅万物的软件很少，用的很顺滑的工具也非常的少。于是想开发软件来实现，但是服务器维护费用也是非常高的，所以想做一个可以订阅付费，但是作为个人开发者，开通支付渠道门槛非常高。于是在网上摸索了很久，找到了一个基本可行的方案，v2geek「收费5%还是有点高的」。他基本满足我的需求，但是没有提供任何开发的接口，不能和软件体系闭环。于是我采用了爬虫技术，基本实现了平台和软件的闭环，可以达到在软件上支付订阅费用，立马给订阅者分发授权码!一整套操作，不需要任何人工操作。 #coding=utf-8 import requests import re from bs4 import BeautifulSoup import uuid class V2GeeKPay(object): def __init__(self, cookies, project=\"\"): self.cookies = cookies self.headers = { \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\", \"accept-encoding\": \"gzip, deflate, br\", \"accept-language\": \"zh-CN,zh;q=0.9,und;q=0.8,zh-Hans;q=0.7,en;q=0.6\", \"cache-control\": \"max-age=0\", \"cookie\": \"_sessions={}\".format(cookies), \"referer\": \"https://v2geek.com/udmin/projects\", \"sec-ch-ua-mobile\": \"?0\", \"sec-ch-ua-platform\": \"Linux\", \"sec-fetch-dest\": \"document\", \"sec-fetch-mode\": \"navigate\", \"sec-fetch-site\": \"same-origin\", \"sec-fetch-user\": \"?1\", \"upgrade-insecure-requests\": \"1\", } flag, self.project_list, self.user_name = self.get_project_list() if not flag: raise ValueError(\"cookie过期，请检查\") if project != \"\": self.set_project(project) def set_project(self, project): project_exist = False for project_obj in self.project_list: if project_obj[\"key\"] == project: self.pay_js = \"https://v2geek.com/{}/{}/widget.js\".format(self.user_name, project) self.login_url = \"https://v2geek.com/users/sign_in\" self.import_url = \"https://v2geek.com/udmin/projects/{}/licenses/import\".format(project) self.project_url = \"https://v2geek.com/udmin/projects/{}\".format(project) self.order_url = \"https://v2geek.com/udmin/orders\" self.project = project project_exist = True break if not project_exist: raise ValueError(\"当前用户不存在此项目，请检查\") def get_project_list(self): \"\"\"获取当前用户的项目以及用户名\"\"\" project_list_url = \"https://v2geek.com/udmin/projects\" session = requests.Session() try: response = str(session.get(project_list_url, headers=self.headers, verify=False).content, encoding=\"utf-8\") html_obj = BeautifulSoup(response, \"html.parser\") tr_list = html_obj.select(\"tbody\")[0].select(\"tr\") dict_project_info = { 0: \"name\", 1: \"price\" } user_name = \"\" project_list = [] for tr in tr_list: temp = {} for idx, td in enumerate(tr.select(\"td\")): if idx in dict_project_info: pro_key = dict_project_info[idx] temp[pro_key] = td.text.strip().replace(\"￥\",\"\").replace(\"元\",\"\") if pro_key == \"name\": key_list = td.select(\"a\")[0].get(\"href\").split(\"/\") if user_name != \"\": user_name = key_list[1] temp[\"key\"] = key_list[2] project_list.append(temp) return True, project_list, user_name except: return False, [], \"\" def generateAuthToken(self, numbers=100): \"\"\"使用uuid算法自动生成authToken \"\"\" return [uuid.uuid4().hex for i in range(numbers)] def import_auth_token(self, auth_token_list): # 自动生成一系列的auth_token值，并分发到系统以便不断的扩充auth_token的值，并将值存入系统 # 获取token值 saved_token_list, unused_token, rest_token = self.get_auth_token_list() if rest_token != \"\": data = { \"utf8\": (None, \"\u0026#x2713;\"), \"authenticity_token\": (None, rest_token), \"licenses\": (None, \"\\n\".join(auth_token_list)), \"commit\": (None, \"提交\") } session = requests.Session() session.post(self.import_url, data=data, headers=headers, verify=False) print(\"导入成功\") return True, \"success\" else: print(\"cookie过期\") return False, \"cookie已过期，请联系工程师处理\" def get_auth_token_list(self): \"\"\" 获取账户的相关信息，以便能够实时进行激活处理 获取成功则返回当前的token,可以用于导入auth_token \"\"\" session = requests.Session() try: response = str(session.get(self.project_url, headers=self.headers, verify=False).content, encoding=\"utf-8\") html_obj_first = BeautifulSoup(response, \"html.parser\") page = html_obj_first.select(\".pagination\") meta_list = html_obj_first.select(\"meta\") rest_token = \"\" html_obj_list = [html_obj_first] for meta in meta_list: if meta.get(\"name\") == \"csrf-token\": rest_token = meta.get(\"content\") if len(page): page_num = int(page[0].select(\"a\")[-1].get(\"href\").split(\"=\")[1].strip())+1 for i in range(2, page_num): response = str(ses","date":"2023-02-19","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/:1:1","tags":["技术","周报","启示"],"title":"2023年第7周, 新的旅途","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/"},{"categories":["weekly"],"content":"开发一款RSS订阅软件 在这信息爆炸的时代，我们身边围绕着十分多的信息，加上推荐系统不断在为我们构建信息围城，我们需要寻找更好的阅读体验的方式，去打破信息围城，以突破信息边界，让我们和世界的信息差不断缩小。有时候也在迷茫，想寻找更好的资讯渠道，比如优质博主，优质信息。知识付费盛行，导致优质信息获取进一步变得十分困难。所以内心一直在想做一款能够对内容进行涮选的rss订阅软件，来丰富自己的阅读，并提升阅读体验和更快的找到优质的信息。 ","date":"2023-02-19","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/:1:2","tags":["技术","周报","启示"],"title":"2023年第7周, 新的旅途","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC7%E5%91%A8/"},{"categories":["weekly"],"content":"本周报分享每周所学所知所闻所感，时间范围是 2023-02-06 到 2023-02-12 会记录一些工作及生活上有意思的事情。 本周报每周日晚上发布，会同步到本人博客中 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"见闻 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"公司总结会 在公司总结会上，我那吞吞吐吐的表达不清的弱势，表现得淋漓尽致。反观同事的表述，层层深入，有条有据，每一句话都说到了点子上。就觉得自己除了技术，还有其他方面的能力需要进一步加强。 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:1:1","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"想开发一款跨平台的终端 在 mac 上有一款很好用的终端工具 Warp 但是 windows 上的好用的终端工具还非常的少，因此想自己使用 rust 开发一款终端工具，能够做到跨平台，使用简单等就好。 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:1:2","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"分享 像写代码一样写技术文章 go语言学习笔记 ","date":"2023-02-12","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/:2:0","tags":["技术","周报","启示"],"title":"2023年第6周, 重拾方向","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC6%E5%91%A8/"},{"categories":["weekly"],"content":"本周报分享每周所学所知所闻所感，时间范围是 2023-01-30 到 2023-02-05 会记录一些工作及生活上有意思的事情。 本周报每周日晚上发布，会同步到本人博客中 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["weekly"],"content":"见闻 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["weekly"],"content":"公司裁员 周四晚上准备下班，同事主动要求要和我一起下班回家，事出异常必有妖。下楼后，他和我说，他被裁员了，顿时我一懵逼。众所周知，我们公司是出了名的养老公司，今年居然裁员了，而且是裁了和我同一届不满一年的员工。这个事情，在我心里久久不能忘怀，生怕这柄达摩克利斯之剑，到我头上。 之后，仔细思考了一下，自己并不是在做公司的核心业务啊，可替换性非常大「需要时刻保持职业危机感」，而且职业发展空间不是很大。于是心里暗下决定，准备用一年的时间来转换自己的技术栈，争取在明年具备跳槽的资格。 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:1:1","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["weekly"],"content":"编程技术思考 这几年，技术进步不是很大，学习了go, rust, c等语言的基础语法，但是没有一些可以用于实战的项目来磨练我的技术。准备今年安排深入学习下go,rust,c并以项目进行驱动，学习下k8s和docker相关知识，并完善网络和linux相关知识栈。在学习语言的同时还需要完善编程模式，软件工程，算法等方面的知识，需要学习和做的事情很多。 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:1:2","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["weekly"],"content":"分享 一个程序员up主的笔记地址 混沌工程 ","date":"2023-02-05","objectID":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/:2:0","tags":["技术","周报","启示"],"title":"2023年第5周，暗流涌动","uri":"/weekly/2023%E5%B9%B4%E7%AC%AC5%E5%91%A8/"},{"categories":["思考"],"content":"Dear Ethan: 又到了充满期待的新的一年，过去的一年你过得还好吗？在往年的年终总结中，你会对即将到来的一年许下满满的期待。很明显，去年的你又是欠下满满债务的你。选择在你28岁的中点写一封信给自己，这更私人，但也更贴近你的内心。 ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:0:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["思考"],"content":"命途多舛，何以不甘 又一年的时间，你经历了不同的事情，遇到了不同的人，了解了不同的故事，现在轮到你说一说自己的故事了。也许都听过关于西西弗斯的故事，他的一生就是不断将巨石推到山顶，又不得不经受巨石滚落，再将石头推向山顶，这样一个荒诞的周而复始的故事。这也许，也是我们每一个人所需要经历的人生。 三月到五月的你，在小论文、毕业论文修改和实验中度过，那时的你，年轻气盛，因为一点小小的观点和老师争吵的面红耳赤。六月份经历了毕业的狂欢，阔别了昔日一起学习的良师益友，与好友约定毕业旅行，因囊中羞涩与疫情的封控而取消。急忙奔赴职场，结实新的朋友，重新投入到自我的升华之中。总的来说，去年的你，经历了人生中的两件大事：毕业和工作，再次完成学生到职场人身份的转变，其它的都是一地鸡毛。 这一年中失去的东西太多太多，任何一点细小的死亡与崩坏都会变得不可承受，这大概就是去年的一个缩影吧，巨石一次次的滚动，我们一次次的再上路。真的很想努力，但满满的无力感。这种无力感，年复一年，细细沉思，最早可追溯到2015年，那是我第一次深刻体会这种无力感。如今七年已过，你仍旧在与这种无力感继续搏斗着。 此前的每一个人生阶段—-初中，高中，大学，似乎总是被安排着走的，大的方向永远是一年比一年好。那份不甘于现实的热情，还能继续保持，也许正是因为不曾经历大的挫折。仔细回忆过往的人生，之前的你确实保持着点自我。那会儿呢，只需要考虑自己就已经足够了，家人永远是不断给予付出的那一方，所以那会儿做什么事都是那么天真吧！这份自我得益于你的少年意气，得益于家庭给你的支撑，也得益于时代的滚滚向前。但人生或命运从来就没有承诺过谁，总会往更好的方向发展。巨石总会滚落，而明天一早睁眼，我们依旧需要推着巨石往上。 ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:1:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["思考"],"content":"肩负起自己的责任 去年的你，每一天都在慌慌张张中度过，连家人都没能好好陪伴，也没有很好的意识到，父母的年纪已经到了颐养天年的时刻，我们需要无时不刻的关注着，陪伴着他们。而你每一天都在焦虑中挣扎，却无法鼓起勇气，让现在的你有所改观，因为你此刻内心是害怕的，害怕试错的代价太大，害怕失败，害怕被人嘲笑。可是，正如上面所说，人生或命运从来就没有承诺过谁，总会往更好的方向发展，所以今年的你，一定要鼓起勇气做出一点改变啦！ 我知道在过去的一年，你无数次打开B站，似乎想要寻找什么答案，可是刷了很久，焦虑一点没减少。事实一次次的告诉你，既然别人无法明确的告诉你，那你就要学会戴着镣铐和生活共舞，不是吗？毛姆在写《月亮与六便士》的时候，大概忘了在理想和现实中间还有责任。他没有告诉你站在路口，抬头是月亮，低头是捡硬币，责任在肩膀上压着，那你该往哪儿走。你唯一确定的是，你想负起这个责任。因为曾经家人的支持是你的底气，你今天，同样想成为家人的底气。 ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:2:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["思考"],"content":"所谓成长，接受自我 直到现在我才真正的意识到，所谓的成长就是认知的不断升级。只有当你明白这个道理，这个世界才开始真正的展开在你的眼前，原来以前认为错误的事情，原来也可以是对的「之前和老师争论的面红耳赤」。你不再为某一个你不认同的点去争论，慢慢的学会去理解别人，尊重别人，倾听大家的声音，不再自我，这已经是你最大的成长了。到了这个年纪才谈成长，这也许是一件过于奢侈的事情了。有很多很多的人，已经过早的品尝了世间的滋味。但对于刚入社会的我来说，考验才刚刚开始。成长不是随着年龄的增长，被社会打磨成一样的世故和圆滑，而是在生命的成熟中，仍有一颗纯真的童心和一颗善良的爱心。你想得到月亮，即使如此的平凡，不能起飞，也要努力的走着，跑着，伸手去够，去摘。即使经历过种种不顺，还是会有好事发生，会有新的缘分，新的身份，新的挑战，我不认输，你也不要，好吗？ ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:3:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["思考"],"content":"寄语未来 2023年，愿你在不平和焦虑的时候，能记起你的初心和梦想，然后大踏步的坚持走向明天！！！ ","date":"2023-01-08","objectID":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/:4:0","tags":["成长","反思","思考"],"title":"写在28岁的中点","uri":"/%E5%86%99%E5%9C%A828%E5%B2%81%E7%9A%84%E4%B8%AD%E7%82%B9/"},{"categories":["读后感"],"content":"务实的哲学 团队信任对于创造力和协作至关重要，关键时刻信任的破坏几乎无法修复 提供选择，别找借口– 小黄鸭编程 破窗理论– 不要因为一些危急的事情，造成附加伤害，尽可能控制软件的熵 人们都觉得，加入一个推进中的成功项目更容易一些（煮石头汤的故事） 永远审视项目，不要做温水青蛙，先养成仔细观察周围环境的习惯，然后再项目中这样做 知识和经验是你最重要的资产，但是它们是时效资产，学习新事物的能力是你最重要的战略资产。 知识组合： 定期投资–安排一个固定的时间和地点学习 每年学习一门新语言 每月读一本技术书 读非技术书 上课– 了解公司之外的人都在做什么 尝试不同的环境 与时俱进–关心最新技术的进展 想法的交叉是很重要的 批判性思维–批判性思考独到的和听到的东西 多样化– 熟悉的技能越多越好 风险管理–不同技术在高风险高回报到低风险低回报区间均匀分布，不要把技术鸡蛋放在一个篮子里 低买高卖–在一项新兴技术流行之前就开始学习，不过这是押宝 重新评估调整–不断刷新自己的知识库 批判性思维 五次为什么 谁从中收益 有什么背景 什么时候在哪里工作可以工作起来 为什么是这个问题 写一个大纲， 问自己：这是否用正确的方式表达了我想表达的东西，以及现在是表达这个东西的好时机吗？ ","date":"2023-01-02","objectID":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/:1:0","tags":["成长","笔记","反思","读后感"],"title":"读《程序员修炼之道》","uri":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/"},{"categories":["读后感"],"content":"务实的方法 ","date":"2023-01-02","objectID":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/:2:0","tags":["成长","笔记","反思","读后感"],"title":"读《程序员修炼之道》","uri":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/"},{"categories":["读后感"],"content":"ETC（easy to change） 核心知道思想 DRY(Don’t repeat yourself) 正交性 良好设计中，数据库相关代码应该和用户界面保持正交， 当系统的组件相互之间高度依赖时，就没有局部修理这回事。 ","date":"2023-01-02","objectID":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/:2:1","tags":["成长","笔记","反思","读后感"],"title":"读《程序员修炼之道》","uri":"/%E8%AF%BB%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/"},{"categories":["weekly"],"content":"本期主要记录自己在最近一周的所见所闻所思。尤其是自己对未来职业生涯的未知。 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:0:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"关于个人的发展 入司培训在这周已经如火如荼的展开了。这也标志着我正式踏入了网络安全行业，我是以开发工程师的身份进入的，但这确实我喜欢的一个特种行业。在安全行业中，懂开发的安全工程师是一个非常稀少的人群，这也是我接下来发展的方向。 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:1:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"最近的焦虑 最近十分的焦虑，一直在为自己之后的发展而发愁，这可能是我很自卑的缘故吧！于是我在B站大学收集了关于自己想学的许多的课程。在这里我进行分享下我收集的课程列表： ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:2:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"编程相关: C++教程：C++ Primer Plus(第六版)教程 算法与数据结构教程 编译原理（哈工大） ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:2:1","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"深度学习相关: ETH机器学习 2022NJUNLP夏令营 统计学习方法·第2版 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:2:2","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"网络安全相关: 最新Kail渗透测试安全工程师入门就业课程 SRC漏洞挖掘教程 渗透测试之皮卡丘靶场——Web从入门到放弃 我也将会在接下来的7，8，9月份中，制定严格的计划来完成一下学习和自我提升计划。计划如下： 7，8月份完成： C++教程：C++ Primer Plus 统计学习方法：第2版 SRC漏洞挖掘教程 9，10月份完成： 算法与数据结构教程 渗透测试之皮卡丘靶场——Web从入门到放弃 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:2:3","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"关于代码和技术 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:3:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"推荐化RSS 这个项目是我想利用项目来提升自己的技术。这个项目我是要带两个学弟一起弄，但是最近我发现沟通成本真的好大啊！可能是因为我们并没有项目合作的经验，大家都是单打独斗出来的，对这个产品不敢大胆的自定义。 这种感觉真的很熟悉，像是突然回到了，大学的时候和思彤一起想做一个相册web软件一样的感觉，最后，这个项目因为合作问题而难产。 这些经历，从现在的角度看来，无不是因为我的退缩和畏难的性格特点导致的。细想我走到今天真的很多决定都是因为我的胆小害怕导致的。这几天的培训也讲了相关的问题，我觉得我是一个固定思维大于发展思维的人。自己很想发展但是由于各种固定思维的限制，从而不敢大胆的迈出自己的脚步。这几天的课，给我的启示很多，既然今天的我已经走入了一个中等偏上的平台，我就应该利用好这个平台，努力完成属于自己的蜕变。 回到项目的问题，我觉得我可能是对学弟抱有了过高的期待，导致他们对项目丧失了主人翁思维。我应该自己先把这个软件做到一定的程度，之后需要加功能和改版的时候，可以带着他们一起改动，之后可以慢慢的培养他们的主人翁思维，这样的合作可能会更好。 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:3:1","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["weekly"],"content":"给自己的话 每天需要抱有感恩的心，对这个世界和人需要有敬畏。 在人面前交流沟通，不需要紧张，大家都是公平的，只是表达自我而已，又没做什么对不起别人的事情。 要善于掩饰自己，不要让自己的菱角刺到朋友，使他成为了敌人。 ","date":"2022-07-10","objectID":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/:4:0","tags":["技术","周报","启示"],"title":"第1期,跨入网络安全行业","uri":"/weekly/2022%E5%B9%B4%E7%AC%AC28%E5%91%A8/"},{"categories":["防失业"],"content":"初试 - 文件变化后 server 自动重启 本源码系列是基于 Django4.0 的源码，可以自行到django 官方下载。 在此之前，不妨先了解下 django 是如何做到自动重启的 ","date":"2022-06-28","objectID":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/:1:0","tags":["笔记","技术","源码"],"title":"Django源码系列：文件变化后server自动重启机制","uri":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/"},{"categories":["防失业"],"content":"开始 django 使用 runserver 命令的时候，会启动俩个进程。 runserver 主要调用了 django/utils/autoreload.py 下 main 方法。 至于为何到这里的，我们这里不作详细的赘述，后面篇章会进行说明。 主线程通过 os.stat 方法获取文件最后的修改时间进行比较，继而重新启动 django 服务（也就是子进程）。 大概每秒监控一次。 # django/utils/autoreload.py 的 reloader_thread 方法 def reloader_thread(): ... # 监听文件变化 # -- Start # 这里主要使用了 `pyinotify` 模块，因为目前可能暂时导入不成功，使用 else 块代码 # USE_INOTIFY 该值为 False if USE_INOTIFY: fn = inotify_code_changed else: fn = code_changed # -- End while RUN_RELOADER: change = fn() if change == FILE_MODIFIED: sys.exit(3) # force reload elif change == I18N_MODIFIED: reset_translations() time.sleep(1) code_changed 根据每个文件的最后修改时间是否发生变更，则返回 True 达到重启的目的。 ","date":"2022-06-28","objectID":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/:1:1","tags":["笔记","技术","源码"],"title":"Django源码系列：文件变化后server自动重启机制","uri":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/"},{"categories":["防失业"],"content":"父子进程\u0026多线程 关于重启的代码在 python_reloader 函数内 # django/utils/autoreload.py def restart_with_reloader(): # 在这里开始设置环境变量为true new_environ = {**os.environ, DJANGO_AUTORELOAD_ENV: \"true\"} args = get_child_arguments() #获取执行的命令参数 # 重启命令在这里开始生效 while True: p = subprocess.run(args, env=new_environ, close_fds=False) if p.returncode != 3: return p.returncode def run_with_reloader(main_func, *args, **kwargs): signal.signal(signal.SIGTERM, lambda *args: sys.exit(0)) # 刚开始 DJANGO_AUTORELOAD_ENV是没有被设置为true的所以这里会进入到else里。 try: if os.environ.get(DJANGO_AUTORELOAD_ENV) == \"true\": reloader = get_reloader() logger.info( \"Watching for file changes with %s\", reloader.__class__.__name__ ) start_django(reloader, main_func, *args, **kwargs) # 开启django服务线程 else: exit_code = restart_with_reloader() sys.exit(exit_code) # 0为正常退出，其他的会抛出相关的错误 except KeyboardInterrupt: pass 程序启动，因为没有 RUN_MAIN 变量，所以走的 else 语句块。 颇为有趣的是，restart_with_reloader 函数中使用 subprocess.run 方法执行了启动程序的命令（ e.g：python3 manage.py runserver ），此刻 RUN_MAIN 的值为 True ，接着执行 _thread.start_new_thread(main_func, args, kwargs) 开启新线程，意味着启动了 django 服务。 如果子进程不退出，则停留在 run 方法这里（进行请求处理），如果子进程退出，退出码不是 3，while 则被终结。反之就继续循环，重新创建子进程。 ","date":"2022-06-28","objectID":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/:1:2","tags":["笔记","技术","源码"],"title":"Django源码系列：文件变化后server自动重启机制","uri":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/"},{"categories":["防失业"],"content":"总结 以上就是 django 检测文件修改而达到重启服务的实现流程。 结合 subprocess.run 和 环境变量 创建俩个进程。主进程负责监控子进程和重启子进程。 子进程下通过开启一个新线程（也就是 django 服务）。主线程监控文件变化，如果变化则通过 sys.exit(3) 来退出子进程，父进程获取到退出码不是 3 则继续循环创建子进程，反之则退出整个程序。 好，到这里。我们勇敢的迈出了第一步，我们继续下一个环节！！！ ヾ(◍°∇°◍)ﾉﾞ ","date":"2022-06-28","objectID":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/:1:3","tags":["笔记","技术","源码"],"title":"Django源码系列：文件变化后server自动重启机制","uri":"/django%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B8%80/"},{"categories":["思考"],"content":"从认识到双向链接开始我先使用了 obsidian,然而对于我这种懒癌晚期的人来说，需要结构化的记录，真的不太适合我「取一个好听的名字真的太难了」。当然有一说一，双链这个观点真的是太妙了。 现在的我已经全面转向了 logseq 来进行笔记记录，不得不说这种支持自定义代码的笔记真的不错「虽然我到目前为止使用最多的是高级查询和TODO这两个功能，记录笔记的话只是零星记录了几句话，并没有详细的记录或者输出一些东西。」。在 logseq 中是以日期为主线的，这免去了我对要写的内容的抽象主题的负担。 ","date":"2022-06-16","objectID":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/:0:0","tags":["成长","反思","思考"],"title":"关于周报这种小事","uri":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/"},{"categories":["思考"],"content":"工作日报周报 首先对任务进行分类，在学习了 Logseq 的高级查询语法并了解其能力之后，我决定使用#tag这种形式来组织个人任务和工作任务，属于工作任务的会标记上#work标签，个人任务就不进行标签。 首先就是工作，这个是大块内容，我目前使用 logseq 生成日报\u0026周报，用于之后提交到绩效评估系统中。 ","date":"2022-06-16","objectID":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/:1:0","tags":["成长","反思","思考"],"title":"关于周报这种小事","uri":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/"},{"categories":["思考"],"content":"日报/周报代码 日报和周报代码上只有 inputs[:yesterday]更改成 inputs[:7d]即可。 #+BEGIN_QUERY { :title \"查询昨天完成的任务\" :query [:find (pull ?b [*]) :in $ ?start ?end :where [?b :block/marker ?m] [?b :block/page ?p] [?p :page/journal? true] [?p :page/journal-day ?d] [(\u003e= ?d ?start)] [(\u003c= ?d ?end)] [?b :block/path-refs [:block/name \"work\"]] [(= \"DONE\" ?m)] ] :inputs [:yesterday :today] } #+END_QUERY 效果图如下： ","date":"2022-06-16","objectID":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/:1:1","tags":["成长","反思","思考"],"title":"关于周报这种小事","uri":"/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%90%AF%E5%91%A8%E6%8A%A5/"},{"categories":["成长"],"content":"在重听李沐老师的《Resnet 论文精读》这一课的时候，ps:「之前没有好好读，:\u003e)羞耻」。在讲到双栏论文中第一页的第二栏最上面，这个位置在学术界是非常重要的。提到了 Randy Pausch 教授在图形学开创了这一风格的写法，然后提到了他的最后一课「深刻印象」。 于是我从 cmu 网站中找到了当年演讲的材料，并完整的看了视频，这份笔记是 Randy 的人生经验和建议的抄录。 ","date":"2022-05-29","objectID":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/:0:0","tags":["成长","思考","人生建议"],"title":"Randy Pausch 教授的最后一课","uri":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/"},{"categories":["成长"],"content":"人生经验 Have something to bring to the table, because that will make you more welcom. 你必须要有一些真本领，这样可以让你更受欢迎。 You’ve got to get the fundamentals down because otherwise the fancy stuff isn’t going to work. 你必须练好基本功，否则后面的事情都不会发生。 That was a bit of a setback. But remember, the brick walls are there for a reason. The brick walls are not there to keep us out. The brick walls are there to give us a chance to show how badly we want something. Becuase the brick walls are there to stop the people who don’t want it badly enough. They’re there to stop the other people. Remember brick walls let us show our dedication. They are there to separate us from the people who don’t really want to achieve their childhood dreams. 你总会遇到挫折。但是记住，它们的出现不是没有原因的。砖墙并不是为了挡住我们。它在那里，只是为了测试，我们的决心到底有多迫切。它在那里挡住那些没有强烈决心的人。它不让那些人通过。记住，砖墙的存在是为了显示我们自己付出的决心。它使得我们，同那些并不真的想实现梦想的人得以区分。 ","date":"2022-05-29","objectID":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/:1:0","tags":["成长","思考","人生建议"],"title":"Randy Pausch 教授的最后一课","uri":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/"},{"categories":["成长"],"content":"为人处世的建议 helping others. 帮助他人。 never lose the childlike wonder. It’s what drives us. 永远不要失去好奇心，它是人类前进的动力。 Loyalty is a two way street. 诚以待人，这样别人也会忠实的对待你。 Never give up. 永远不要放弃 You can’t get there alone. People have to help you. You get people to help you by telling the truth. 你不能单打独斗，必须有人来帮你。只要你讲真话，就会有人来帮你。 Apologize when you screw up and focus on other people, not on yourself. 当你把事情搞砸，首先要向别人道歉，首先关心他们的损失，而不是你自己的损失。 When you do the right thing, good stuff has a way of happening. 如果你做了正确的事，好的结果自然会发生。 Get a feedback loop and listen to it. 注意倾听反馈。 Show gratitude. 感恩 Don’t complain. Just work harder. 不要抱怨，而要加倍努力。 Be good at something, it makes you valuable. 要有一技之长，它使你有价值。 Work hard. 努力再努力。 Find the best in everybody. 注意发现他人的优点。 Be prepared. Luck is truly where preparation meets opportunity. 做好准备。所谓幸运，真的是机会和准备的结合。 ","date":"2022-05-29","objectID":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/:2:0","tags":["成长","思考","人生建议"],"title":"Randy Pausch 教授的最后一课","uri":"/%E5%85%B0%E8%BF%AA%E6%95%99%E6%8E%88%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E8%AF%BE/"},{"categories":["技术"],"content":"本文介绍 Tranformer 的代码。 ","date":"2022-05-28","objectID":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:0:0","tags":["技术","深度学习","笔记","源码阅读"],"title":"transformer源码阅读","uri":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["技术"],"content":"模型结构 Encoder 将输入序列$(x_{1},\\cdots,x_{n})$ 映射成一个连续的序列$z = (z_{1},\\cdots,z_{n})$。而 Decoder 根据$z$来解码得到输出序列$(y_{1},\\cdots,y_{m})$。Decoder 是自回归的(auto-regressive)–它会把前一个时刻的输出作为当前时刻的输入。Encoder-Decoder 结构模型的代码如下： class EncoderDecoder(nn.Module): \"\"\" 标准的Encoder-Decoder架构。 \"\"\" def __init__(self, encoder, decoder, src_embed, tgt_embed, generator): super(EncoderDecoder,self).__init__() self.encoder = encoder self.decoder = decoder # 源语言和目标语言的embedding self.src_embed = src_embed self.tgt_embed = tgt_embed # generator主要是根据Decoder的隐状态输出当前时刻的词(单个词) # 基本的实现就是隐状态输入一个全连接层，然后接一个softmax变成概率 self.generator = generator def forward(self, src, tgt, src_mask, tgt_mask): # 首先调用encode方法对输入进行编码，然后调用decode方法进行解码 return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask) def encode(self, src, src_mask): # 调用self.encoder函数 return self.encoder(self.src_embed(src), src_mask) def decode(self, memory, src_mask, tgt, tgt_mask): # 调用self.decoder函数 注意⚠️：这里定义的memery是encoder的输出结果。 return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask) EncoderDecoder 定义了一种通用的 Encoder-Decoder 架构，具体的 Encoder、Decoder、src_embed、target_embed 和 generator 都是构造函数传入的参数。这样我们做实验更换不同的组件就会更加方便。 class Generator(nn.Module): def __init__(self, d_model, vocab): super(Generator, self).__init__() # d_model是Decoder输出的大小，vocab是词典的大小 self.proj = nn.Linear(d_model, vocab) def forward(self, x): return F.log_softmax(self.proj(x), dim=-1) 注意 ⚠️：Generator 返回的是 softmax 的 log 值。在 pytorch 中为了计算交叉熵损失，有两种方法。第一种方法就是 nn.CrossEntropyLoss(),一种是使用 NLLLoss()。第一种方法更加容易懂，但是在很多开源代码里第二种更常见。 CrossEntropyLoss: criterion = nn.CrossEntropyLoss() x = torch.randn(1,5) # 服从0-1的正太分布。 y = torch.empty(1, dtype = torch.long).random_(5) loss = criterion(x,y) 比如上面的代码，假设是 5 分类问题，x表示模型的输出 logits(batch=1)，而 y 是真实分类的下标(0-4)。实际的计算过程为：$loss = -\\sum^{5}{i=1}y{i}log(softmax(x_{i}))$。 NLLLoss(Negative Log Likelihood Loss)是计算负 log 似然损失。它输入的 x 是 log_softmax 之后的结果（长度为 5 的数组），y 是真实分类（0-4），输出就是 x[y]。因此代码为： m = F.log_softmax(x, dim=1) criterion = nn.NLLLoss() x = torch.randn(1, 5) y = torch.empty(1, dtype = torch.long).random_(5) loss = criterion(m(x), y) Transformer 模型也是遵循上面的架构，只不过它的 Encoder 是 N(6)个 EncoderLayer 组成，每个 EncoderLayer 包含一个 Self-Attention SubLayer 层和一个全连接 SubLayer 层。而它的 Decoder 也是 N(6)个 DecoderLayer 组成，每个 DecoderLayer 包含一个 Self-Attention SubLayer 层、Attention SubLayer 层和全连接 SubLayer 层。如下图所示。 ","date":"2022-05-28","objectID":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:1:0","tags":["技术","深度学习","笔记","源码阅读"],"title":"transformer源码阅读","uri":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["技术"],"content":"Encoder 和 Decoder Stack 前面说了 Encoder 和 Decoder 都是由 N 个相同结构的 Layer 堆积(stack)而成。因此我们首先定义 clones 函数，用于克隆相同的 SubLayer。 def clones(module, N): # 克隆N个完全相同的SubLayer，使用了copy.deepcopy return nn.ModuleList([copy.deepcopy(module) for _ in range(N)]) 这里使用了 nn.ModuleList, ModuleList 就像一个普通的 Python 的 List，我们可以使用下标来访问它，它的好处是传入的 ModuleList 的所有 Module 都会注册的 PyTorch 里，这样 Optimizer 就能找到这里面的参数，从而能够用梯度下降更新这些参数。但是 nn.ModuleList 并不是 Module（的子类），因此它没有 forward 等方法，我们通常把它放到某个 Module 里。接下来定义 Encoder: class Encoder(nn.Module): # Encoder是N个EncoderLayer的stack def __init__(self, layer, N): super(Encoder, self).__init__() # layer是一个SubLayer，我们clone N个 self.layers = clones(layer, N) # 再加一个LayerNorm层 self.norm = LayerNorm(layer.size) def forward(self, x, mask): # 逐层进行处理 for layer in self.layers: x = layer(x, mask) # 最后进行LayerNorm return self.norm(x) Encoder 就是 N 个 SubLayer 的 stack，最后加上一个 LayerNorm。我们来看 LayerNorm: class LayerNorm(nn.Module): def __init__(self, features, eps=1e-6): super(LayerNorm, self).__init__() self.a_2 = nn.Parameter(torch.ones(features)) self.b_2. = nn.Parameter(torch.zeros(feagures)) self.eps = eps def forward(self, x): mean = x.mean(-1, keepdim = True) std = x.std(-1, keepdim = True) return self.a_2 * (x - mean)/(std+self.eps) + self.b_2 LayerNorm：假设数据为[batch_size, unit, 1, features]，这里是对整个样本进行 normalization。这里的 Layer Normalization 不是 Batch Normalization。 x -\u003e attention(x) -\u003e x+self-attention(x)[残差] -\u003e layernorm(x+self-attention(x)) =\u003e y y -\u003e dense(y) -\u003e y+dense(y) -\u003e layernorm(y+dense(y)) =\u003e z(输入下一层) 这里稍微做了一点修改， 在 self-attention 和 dense 之后加了一个 dropout 层。另一个不同支持就是把 layernorm 层放到前面了。这里的模型为： x -\u003e layernorm(x) -\u003e attention(layernorm(x)) -\u003e a + attention(layernorm(x)) =\u003e y y -\u003e layernorm(y) -\u003e dense(layernorm(y)) -\u003e y+dense(layernorm(y)) 原始论文的 layernorm 放在最后；而这里把它放在最前面并且在 Encoder 的最后在加了一个 layernorm。这里的实现和论文的实现基本是一致的，只是给最底层的输入 x 多做了一个 LayerNorm，而原始论文是没有的。下面是 Encoder 中的 forward 方法，这样比读者可能会比较清楚为什么 N 个 EncoderLayer 处理完成后还需要一个 LayerNorm。 def forward(self, x, mask): for layer in self.layers: x = layer(x, mask) return self.norm(x) 不管是 Self-Attention 还是全连接层，都首先是 LayerNorm，然后是 Self-Attention/Dense，然后是 Dropout，最好是残差连接。 class SublayerConnection(nn.Module): \"\"\" LayerNorm+sublayer(Self-Attention/Dense) + dropout + 残差连接 为了简单，把LayerNorm放到了前面，这和原始论文稍有不同，原始论文LayerNorm在最后。 \"\"\" def __init__(self, size, dropout): supper(SublayerConnection, self).__init__() self.norm = LayerNorm(size) self.dropout = nn.Droupout(dropout) def forward(self, x, sublayer): # sublayer是传入的参数,之后进行残差连接 return x+self.dropout(sublayer(self.norm(x))) Self-Attention 或者 Dense 并不在这里进行构造，而是放在了 EncoderLayer 里，在 forward 的时候由 EncoderLayer 传入。这样的好处是更加通用，比如 Decoder 也是类似的需要在 Self-Attention、Attention 或者 Dense 前面加上 LayerNorm 和 Dropout 以及残差连接，我们就可以复用代码。但是这里要求传入的 sublayer 可以使用一个参数来调用的函数。 class EncoderLayer(nn.Module): # EncoderLayer由self-attn和feed_forward组成 def __init__(self, size, self_attn, feed_forward, dropout): super(EncoderLayer, self).__init__() self.size = size self.self_attn = self_attn self.feed_forward = feed_forward self.sublayer = clones(SublayerConnection(size, dropout), 2) def forward(self, x, mask): x = self.sublayer[0](x, lambda x:self.self_attn(x,x,x,mask)) return self.sublayer[1](x, self.feed_forward) 为了复用，这里的 self_attn 层和 feed_forward 层也是传入的参数，这里只构造两个 SublayerConnection。forward 调用 sublayer0的call方法，最终会调到它的 forward 方法，而这个方法需要两个参数，一个是输入 Tensor， 一个是一个 callable, 并且这个 callable 可以用一个参数来调用。而 self_attn 函数需要 4 个参数（Query 的输入，key 的输入，Value 的输入和 Mask），因此这里我们使用 lambda 的技巧把它变成一个参数 x 的函数(mask 可以堪称已知的数)。因为 lambda 的形参也叫 x. Decoder class Decoder(nn.Module): def __init__(self, layer, N): super(Decoder, self).__init__() self.layers = clones(layer, N) self.norm = LayerNorm(layer.size) def forward(self, x, memory, src_mask, tgt_mask): for layer in self.layers: x = layer(x, memory, src_mask, tgt_mask) return self.norm(x) Decoder 也是 N 个 DecoderLayer 的 stack，参数 layer 是 DecoderLayer，它也是一个 callable，最终call会调用 DecoderLayer.forward 方法，这个方法需要 4 个参数，输入 x, Encoder 层的输出 memory, 输入 Encoder 的 Mask(src_mask)和输入 Decoder 的 ","date":"2022-05-28","objectID":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:2:0","tags":["技术","深度学习","笔记","源码阅读"],"title":"transformer源码阅读","uri":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["技术"],"content":"MultiHeadedAttention 多头注意力机制 Attention(包括 Self-Attention 和普通的 Attention)可以堪称一个函数，它的输入是 Query，Key，Value 和 Mask，输出是一个 Tensor。其中输出是 Value 的加权平均，而权重来自 Query 和 Key 的计算。具体的计算如下图所示，计算公式为：$$Attention(Q,K,V) = softmax(\\frac{QK^{T}}{\\sqrt{d_{k}}})V$$ 代码为： def attention(query, key, value, mask=None,dropout=None): d_k = query.size(-1) scores = torch.matmul(query,key.transpose(-2,-1))/math.sqrt(d_k) if mask is not None: scores = scores.mask_fill(mask==0,-1e9) p_attn = F.softmax(scores, dim=-1) if dropout is not None: p_attn = dropout(p_attn) return torch.matmul(p_attn,value),p_attn 这里主要的疑问是在score.mask_fill，主要用于把 mask 是 0 的变成一个很小的数，这样后面经过 softmax 之后的概率就很接近零（但是理论上还是用了很少一点点未来的信息）。 之前介绍过，对于每一个 Head，都是用三个矩阵$W^{Q}$，$W^{K}$，$W^{V}$把输入转换成 Q，K 和 V。然后分别用每一个 Head 进行 Self- Attention 的计算，最后把 N 个 Head 的输出拼接起来，最后用一个矩阵$W^{O}$把输出压缩一下。具体计算框架为： 代码如下： class MultiHeadAttention(nn.Module): def __init__(self, h, d_model, dropout=0.1): super(MultiHeadAttention, self).__init__() assert d_model % h == 0 self.d_k = d_model // h # 这里是整除 self.h = h self.linears = clones(nn.Linear(d_model,d_k),4) self.attn = None self.dropout = nn.Dropout(p=dropout) def foward(self, query, key, value, mask=None): if mask is not None: # 所有h个head的mask都是相同的 mask = mask.unsqueeze(1) nbatches = query.size(0) # 1) 首先使用线性变换，然后把d_model分配给h个Head，每个head为d_k=d_model/h query, key, value = [l(x).view(nbatches,-1,self.h,self.d_k).transpose(1,2) for l,x in zip(self.linears,(query, key, value))] # 2) 使用attention函数计算 x, self.attn = attention(query, key, value, mask=mask,dropout = self.dropout) # 3） x = x.transpose(1,2).contiguous().view(nbatches, -1,self.h*self.d_k) return self.linears[-1](x) 我们首先来看构造函数， 这里 d_model(512)是 Multi-Head 的输出大小，因为有 h(8)个 head， 因此每个 head 的 d_k=512/8=64。接着我们构造 4 个(d_model $*$ d_model)的矩阵，后面我们会看到它的用处。最后是构造一个 Dropout 层。 然后我们来看 forward 方法。输入的 mask 是（batch,1,time）的，因为每个 head 的 mask 都是一样的，所以先用 unsqueeze(1)变成(batch,1,1,time)，mask 我们前面已经分析过了。 接下来就是根据输入的 query, key, value 计算变换后的 Multi-Head 的 query, key 和 value。zip(self.linears, (query,key,value))是把(self.linear[0], self.linear[1], self.linear[2])和(query, key, value)放在一起遍历。我们可以只看一个self.linear[0] (query)。根据构造函数的定义，self.linear[0]是一个[512,512]的矩阵，而query是(batch, time, 512)，相乘之后得到的新 query 还是 512 维的向量，然后用 view 把它变成(batch, time, 8, 64)。然后 transpose 成(batch, 8, time, 64)，这是 attention 函数要求的 shape。分别对 8 个 Head，每个 Head 的 Query 都是 64 维。最后使用self.linear[-1]对x进行线性变换，self.linear[-1]是[512, 512]的，因此最终的输出还是(batch, time, 512)。 ","date":"2022-05-28","objectID":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/:3:0","tags":["技术","深度学习","笔记","源码阅读"],"title":"transformer源码阅读","uri":"/transformer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"categories":["思考"],"content":"这一段时间我也一直在思考，毕业之后的发展。读了许多大佬写的博客，想着能够从中汲取一些经验和启发。发现大家都有一个共性就是善于总结和对自己的职业生涯进行了一定的规划，他们清楚的了解自己的定位和未来想要得到什么。我一直坚信花时间来整理状态，是一件很值得投资的事情。这篇文章也相当于研究生生涯总结和职业生涯的开篇吧！ 毕业前的时光算得上是踏上职场前最后的悠闲。尽管对未来充满了希望，与此同时，我的内心也充斥着彷徨。害怕在未来几年一无所成，害怕自己达不到自己所期待的那种境界。每年设定目标，然而能够完成的却寥寥无几。才有了现在对未来的迷茫，心中一腔热血却像苍蝇一样，漫无目的。这可能也是普通人和大佬之间的区别吧！阅读过大佬的文章后，有下面的启示。 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:0:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["思考"],"content":"别多想，多实践 你思考的 90%的问题，至少 1000 年前，先哲们都给了答案。 剩下的 10%，300 年前的哲学家，思想家一定给出了答案。 绝对不存在你思考的问题，历史上的思想家没有给出答案。所以大多数的时候，没看书之前，你的思考，是徒劳的。 大多数时候，我们所思考的问题，前人都已经思考过了。我们需要做的是，踏踏实实的沉下心来，进行学习即可。我们总在思考未来应该如何做才能快速的成长，追求完成一件事情的形式。殊不知未来正是由无数个当下的事情组成的。与其担心未来，还不如沉下心来把当下的事情做到极致，未来一定会出现在你的眼前。 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:1:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["思考"],"content":"尽早规划（长线思维） 怎么过一天，就怎么过一生，如果认为明天或一年之后会有所改变，那么今天的自己是一年前希望看到的自己么。 随着时间的推移，资产（你认为有价值的一切）变得更有价值还是廉价 把每一个场景都看成投资场景，每一个行为当作投资行为，重视它对现在及将来的影响 咱们中国有一个不变的传统就是“五年规划”，国家尚且如此，何况人？所以我们也要及早的对自己进行一个五年规划，这个规划应该是方向性的，不是细节的。细节应当是每年每季度每月具体去完成以达到五年规划中的目标。 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:2:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["思考"],"content":"注重输出 只是看书或者视频，容易造成已经理解了某个知识点的错觉，短期记忆未经加固，很快就会「挥发」 无输出不输入，输出的方式可以是文章或者视频或者闲聊，经过强化后的内容更容易进入长期记忆 输出的过程会联结之前的积累，让知识更扎实，输出过程也会更流畅，输入和输出的比例可以控制在 3:7 在知识库系统的过程中，我们往往过于完美主义，想把知识系统工具一次性构建完整，然后把大量的时间都放在了工具的搭建中，折腾了很多中工具：notion, obsidian, logseq 等。我个人认为，工具是在自己不断的使用的过程中完善的，知识库也是一样，首先我们要有输出，之后在慢慢的进行调整，最后会实现一个理想中适合自己的知识系统的。我在这里建议放弃完美主义，在实践中不断的调整自己调整工具。还有一个就是逃离算法推荐吧，拥抱内容的多元化。 不要只停留在理论上，去实践，会发现更多的问题和挑战，也更有趣味，“what i cannot create, i do not understand”。 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:3:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["思考"],"content":"参考资料 工程师的成长 写在 28 岁边上 技术同学在业务中的成长 用未来的视角来看今天 ","date":"2022-05-15","objectID":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/:4:0","tags":["成长","反思","思考"],"title":"对个人发展的思考","uri":"/%E5%AF%B9%E4%B8%AA%E4%BA%BA%E5%8F%91%E5%B1%95%E7%9A%84%E6%80%9D%E8%80%83/"},{"categories":["技术"],"content":"工作中常需要连接着服务器，比如在深度学习训练模型的过程中，需要长时间连接着服务器，在一段时间没有操作后，ssh 会自动断开。 为了解决这个问题，在网上找到一种配置方法，亲测很久都不会再断开了，在此记录： 众所周知，ssh 是用于与远程服务器建立加密通信通道的，因此配置涉及到服务器和客户端： 服务端 /etc/ssh/sshd_config +ClientAliveInterval 60 # 每60秒发送一个KeepAlive请求 +ClientAliveCountMax 15 # 总时间为：15*60， 15分钟没有操作，终端断开。 # 以下命令重启 sshd 服务 service sshd reload service sshd restart 客户端 ~/.ssh/config # 修改～/.ssh/config配置，对当前用户生效 # 这样配置通配所有服务端 Host * ServerAliveInterval 60 ","date":"2022-05-13","objectID":"/ssh%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/:0:0","tags":["技术","工具","ssh"],"title":"ssh自动断开修复方法","uri":"/ssh%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/"},{"categories":["技术"],"content":"参考文献 SSH 长时间不使用自动断开解决方案 ","date":"2022-05-13","objectID":"/ssh%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/:1:0","tags":["技术","工具","ssh"],"title":"ssh自动断开修复方法","uri":"/ssh%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E4%BF%AE%E5%A4%8D%E6%96%B9%E6%B3%95/"},{"categories":null,"content":"关于我 长期从事⽹络安全与深度学习结合以及网络协议分析相关开发⼯作, 专注⾼速报⽂处理及 DPI 技术, 追求极致性能, 欣赏优雅简洁之美, 重视⽂档. ","date":"2022-01-01","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"成果 Zhou X, Hu Y, Liang W, et al. Variational LSTM enhanced anomaly detection for industrial big data[J]. IEEE Transactions on Industrial Informatics, 2020, 17(5): 3469-3477. Zhou X, Hu Y, Wu J, et al. Distribution Bias Aware Collaborative Generative Adversarial Network for Imbalanced Deep Learning in Industrial IoT[J]. IEEE Transactions on Industrial Informatics, 2022. Liang W, Hu Y, Zhou X, et al. Variational Few-Shot Learning for Microservice-Oriented Intrusion Detection in Distributed Industrial IoT[J]. IEEE Transactions on Industrial Informatics, 2022, 18(8): 5087-5095. ","date":"2022-01-01","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"}]